% \begin{generalinstructions}
% Make sure the notation is consistent, Predefine $\bar{R},I $ for example. Also, look over and rewrite theorems so that they fit together with the notation. Ensure consistency in number of dimensions.
% \end{generalinstructions}



% \begin{generalinstructions}
%     \begin{compactitem}
%         \item \textbf{Returns}
%         \item $P_{t_i}$ : Price at time $t_i$. 
%         \item $t_i$ : time increment
%         \item $R_{t_i}$ : Return over time increment $t_i$.
%         \item $R_{t_i,\mathrm{port}}$ : portfolio return over time increment $t_i$.
%         \item $R_{t_i}^-$ : minimum simple return.
%         \item $R_{t_i}^+$ : maximum simple return.
%         \item $Y_{t_i}$ : log return over time increment $t_i$.
%         \item $Y_{t_i, \mathrm{port}}$  : portfolio log return over time increment $t_i$.
%         \item $Y_{t_i}^-$ :
%         \item $Y_{t_i}^+$ :
%         \item \textbf{Geometric Brownian motion and euler} 
%         \item $S_t$ : stock price at time $t$.
%         \item $\mu$ : drift.    
%         \item $\sigma$ : volatility.
%         \item $W_t$ : Wiener process.
%         \item $s_0$ : initial stock price.
%         \item $\hat{S}(t_i)$ : approximate solution to the \gls{SDE} at time $t_i$.
%         \item $d$: dimension of the \gls{SDE}.
%         \item \textbf{Probability theory}
%         \item $\bar{R}$: extended real line $[-\infty, \infty]$.
%         \item $F$ : \gls{CDF} of a random variable.
%         \item $f$ : \gls{PDF} of a random variable.
%         \item $X$ : random variable usuallt log returns
%         \item $P$ : probability.
%         \item $H$ : 2-place real function.
%         \item $u,v$ : nonempty subsets of $\bar{R}$ (sections of the real line).
%         \item $B$ : rectangle in $\bar{R}^2$.
%         \item $V_H(B)$ : $H$-volume of $B$.
%         \item Return space: (for log returns we have $(-\infty, \infty)$)
%         \item Probability space  : $[0,1]$.
%         \item $U$ : uniformly distributed random variable in probability space.
%         \item $\mathcal{L}$ : likelihood function.
%         \item $l$ : likelihood function value.
%         \item $\theta$ : parameters for a statistical distribution.
%         \item $\hat{\theta}$ : estimated parameters for a statistical distribution.
%         \item \textbf{Copula theory}
%         \item $C$ : copula function.
%         \item $c$ : copula density function.
%         \item $I= [0,1]$ : 
%         \item $H$ distribution function in 2d
%         \item $F,G$ : marginal \gls{CDF}s.
%         \item $\D$ : domain
%         \item $\mathrm{Ran}$ :range
%     \end{compactitem}
% \end{generalinstructions}

In this section, we will introduce the mathematical background needed to understand the methods used in this thesis will be presented. \Cref{sec:MathematicalFinance} will introduce the mathematical finance. \Cref{sec:ProbabilityTheory} will introduce the probability theory, connecting financial returns to statistical distributions. \Cref{sec:CopulaTheory} will introduce copulas and explain their role in modeling dependencies of statistical distributions. \Cref{sec:NeuralNetworks} will introduce \gls{NN}s and how to use them to solve differential equations. \Cref{sec:NeuralCopula} will introduce how to use \gls{NN}s to approximate copulas. Finally, \Cref{sec:GoodnessOfFit} will introduce how to evaluate the goodness of fit of a copula model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Mathematical finance
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Mathematical Finance}\label{sec:MathematicalFinance}
In mathematical finance, one is typically interested in the returns of financial assets over time, rather than their prices, as stated by \Citet[p.~2]{Danielsson2011}. Let $P_{t_i}$ denote the price at time increment $t_i$, where $t_i$ is usually in daily time increments but can represent any unit of time. 

\subsubsection{Returns}
This section introduces different types of returns—simple and log—and their respective properties. These properties include return aggregation over time, portfolio return calculations, the generation of new prices, and bounds for returns. The reason for introducing different types of returns is to show the connections between financial returns and statistical distributions, which in turn connect to the theory of copulas. 

First, we introduce what financial returns on assets are. The return of a financial asset is the relative price change over a given time interval, often expressed as a percentage as \Citet[p.~2]{Danielsson2011} says. One type of return is the simple return, defined in \Cref{def:simpleReturns} as done by \Citet[p.~3]{Danielsson2011}.

\begin{definition}\label{def:simpleReturns}
    \textbf{Simple Returns} \\
    A \emph{simple return} is the percentage change in price over time period $t_i$, indicated by $R_{t_i}$:
    \begin{align*}
        R_{t_i} := \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}}.
    \end{align*}
\end{definition}

To aggregate several simple (daily) returns over some period (e.g., a week), one must construct several change factors that are multiplied together before subtracting one. This aggregation process is described in \Citet[p.~3]{Danielsson2011}, where the aggregated return over $n$ periods is calculated as
\begin{align*}
    R_{t_{i}}(n) = (1+R_{t_{i}})(1+R_{t_{i-1}})(1+R_{t_{i-2}})\dots (1+R_{t_{i-n+1}}) -1 = \frac{P_{t_{i}}}{P_{t_{i-n}}}-1.
\end{align*}

In many situations, it is necessary to calculate the return of an entire portfolio of assets from its underlying asset returns. For simple returns, this is done by calculating a weighted average of the individual asset returns. \citet[p.~3]{Danielsson2011} describes the calculation of the portfolio return $R_{t_i,\mathrm{port}}$ for a portfolio with $K$ different assets as 
\begin{align*}
    R_{t_i,\mathrm{port}} = \sum_{k=1}^K w_k R_{t_i,k}.
\end{align*}

It is often useful to simulate new stock prices by using randomly generated returns. For simple returns, new prices are calculated as
\begin{align*}
    P_{t_{i}} = P_{t_{i-1}}(1+R_{t_{i}}).
\end{align*}

The space in which realizations of returns can be observed differs depending on the type of return. In \Cref{ex:BoundsSimpleReturns}, the range for simple returns is derived. 

\begin{example}\label{ex:BoundsSimpleReturns}
    To determine the bounds for simple returns, we investigate what happens as the stock price moves to zero—corresponding to bankruptcy—and when the stock price moves to infinity. We denote the simple return when the price goes to zero and infinity by $R_t^-$ and $R_t^+$ respectively:   
    \begin{align*}
        R_{t_i}^- = \lim_{P_{t_i} \to 0} \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}} = \frac{0-P_{t_{i-1}}}{P_{t_{i-1}}} = -1 \\
        R_{t_i}^+ = \lim_{P_{t_i} \to \infty} \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}} = \frac{\infty-P_{t_{i-1}}}{P_{t_{i-1}}} = \infty    
    \end{align*}
    Hence, we conclude that $R_t \in [ -1,\infty )$. 
\end{example}

Continuously compounded returns, or so-called logarithmic returns, are often used in financial modeling due to their desirable properties. One such property is that returns are \emph{symmetric}, meaning that positive and negative returns of the same magnitude cancel each other out \citet[p.~4]{Danielsson2011}. Log returns are defined, as done by \citet[p.~3]{Danielsson2011}, in \Cref{def:logReturns}. 

\begin{definition}\label{def:logReturns}
    \textbf{Log Returns} \\
    The logarithm of the gross return, or \emph{log return}, indicated by $Y_{t_i}$:
    \begin{align*}
        Y_{t_i} := \mathrm{log}(1+R_{t_i}) = \mathrm{log} \left(\frac{P_{t_i}}{P_{t_{i-1}}}\right) = \mathrm{log}(P_{t_i}) - \mathrm{log}(P_{t_{i-1}}).
    \end{align*}
\end{definition}

Log returns have the advantage that multi-period (e.g., $n$-period) returns are simply the sum of the one-period returns as shown by \Citet[p.~3]{Danielsson2011}, that is, 
\begin{align*}
    Y_{t_i}(n) = Y_{t_i} + Y_{t_{i-1}} + \dots + Y_{t_{i-n+1}}.
\end{align*}

As illustrated by \citet[p.~4]{Danielsson2011}, the portfolio return is more complicated to compute for log returns because the relationship is not simply a weighted sum:
\begin{align*}
        Y_{t_i,\mathrm{port}} &= \mathrm{log}\left(\frac{P_{t_i,\mathrm{port}}}{P_{t_{i-1},\mathrm{port}}}\right) \neq  \sum_{k=1}^K w_k \mathrm{log}\left(\frac{P_{t_i,k}}{P_{t_{i-1},k}}\right),        
\end{align*}
where 
\begin{align*}
    P_{t_i,\mathrm{port}} &= \sum_{k=1}^K w_k P_{t_i,k}.
\end{align*}


A weighted average only approximately describes the portfolio log returns in terms of the individual returns, as described by \Citet[p.~4]{Danielsson2011},
\begin{align*}
    Y_{t_i,\mathrm{port}} \approx \sum_{k=1}^K w_k R_{t_i,k}.
\end{align*}

The correct relation between portfolio log returns and the log returns of its components is given by first converting the log returns to prices, then calculating the portfolio value, and finally computing the log return from that:
\begin{align*}
    Y_{t_i,\mathrm{port}} = \mathrm{log} \left( \frac{\sum_{k=1}^K w_k P_{t_i,k}}{\sum_{k=1}^K w_k P_{t_{i-1},k}} \right), \quad \text{where} \quad P_{t_i,k} = P_{t_{i-1},k} e^{Y_{t_i,k}}.
\end{align*}
In the above expression, the numerator represents the new portfolio value, while the denominator represents the initial portfolio value. $K \in \mathbb{N}$ is the number of assets in the portfolio, and $w_k$ is the weight of asset $k$ in the portfolio. Note that individual asset prices are updated using their log returns before combining them into the portfolio value. 

In many applications, one wants to simulate returns to generate artificial stock price developments. Log returns from stock prices usually appear to be generated from some bell-shaped probability distribution. This is convenient because one can sample from a probability distribution to simulate log returns for an asset. For example, the well-known Black-Scholes model assumes that stock returns are log-normally distributed—that is, log returns are normally distributed. 

To obtain the price $P_{t_i}$ at the end of time period $t_i$ using a simulated log return $Y_{t_i}$ for that period, one calculates 
\begin{align*}
    P_{t_i} = P_{t_{i-1}} e^{Y_{t_i}}.
\end{align*}

Unlike simple returns, the range in which log returns can be observed is unbounded in both directions. 
\begin{example}
    To see this, we investigate what happens to the returns when the stock price moves to zero (bankruptcy) and to infinity. We denote the log return when the price goes to zero and infinity by $Y_t^-$ and $Y_t^+$ respectively:   
    \begin{align*}
        Y_{t_i}^- = \lim_{P_{t_i} \to 0} \mathrm{log} \left( \frac{P_{t_i}}{P_{t_{i-1}}} \right) = \mathrm{log}(0) = -\infty \\
        Y_{t_i}^+ = \lim_{P_{t_i} \to \infty} \mathrm{log} \left( \frac{P_{t_i}}{P_{t_{i-1}}} \right) = \mathrm{log}(\infty) = \infty    
    \end{align*}
    Hence, we conclude that $Y_{t_i} \in (-\infty,\infty)$. 
\end{example}

To better understand how different types of returns work, \Cref{ex:returnSymmetry}, inspired by \Citet[p.~4]{Danielsson2011}, shows that simple returns are not symmetric, whereas log returns are. 
\begin{example}\label{ex:returnSymmetry}
    \textbf{Symmetry of Returns}\\
    Consider a stock with an initial price $P_0 = 100$, a price after one day $P_1 = 200$, and a price on day two $P_2 = 100$. Let's examine the impact of these price changes on simple and log returns.

    \textbf{Simple Returns}\\
    The return on the first day is
    \begin{align*}
        R_1 = \frac{P_1 - P_0}{P_0} = \frac{200 - 100}{100} = 1 = 100\%.
    \end{align*}
    The return on the second day is
    \begin{align*}
        R_2 = \frac{P_2 - P_1}{P_1} = \frac{100 - 200}{200} = -\frac{1}{2} = -50\%.
    \end{align*}    

    \textbf{Log Returns}\\
    The return on the first day is 
    \begin{align*}
        Y_1 = \log \left( \frac{P_1}{P_0} \right) = \log\left( \frac{200}{100} \right) = \log(2) \approx 69\%.
    \end{align*}
    The return on the second day is
    \begin{align*}
        Y_2 = \log \left( \frac{P_2}{P_1} \right) = \log \left( \frac{100}{200} \right) = \log\left( \frac{1}{2} \right) \approx -69\%.
    \end{align*}
    We observe that log returns are symmetric, so monetary gains and losses of equal magnitude produce log returns of equal magnitude. In contrast, simple returns are not symmetric.
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% GBM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Geometric Brownian Motion}
The symmetry property of log returns is desirable because it means that the log returns can be modeled using a normal distribution. This is convenient because the normal distribution has many useful properties and is easy to work with. Log returns are often used in financial modeling—perhaps most notably in the Black-Scholes model for option pricing—where stock prices are assumed to follow a \gls{GBM}, whose price is lognormally distributed. 

The \gls{GBM} is a stochastic process used to model the evolution of stock prices. It is defined by the stochastic differential equation (SDE)
\begin{align*}
    dS_t &= \mu S_t \,dt + \sigma S_t \,dW_t, \\
    S_0 &= s_0 \in \mathbb{R},
\end{align*}
where $S_t$ is the stock price at time $t$, $\mu \in \mathbb{R}$ is the drift, $\sigma \in \mathbb{R}_+$ is the volatility, and $W_t$ is a Wiener process, as defined by \citet[p.~68]{Bjork2019Edition4}.

The \gls{GBM} has an explicit solution
\begin{align*}
    S_t = s_0 \; \exp\left( \left( \mu - \frac{\sigma^2}{2} \right)t + \sigma W_t \right),
\end{align*}
as stated by \Citet[p.~70]{Bjork2019Edition4}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Euler-Maruyama
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Euler-Maruyama Scheme}\label{sec:EulerMaruyama}
To approximately simulate \gls{SDE}s, the Euler-Maruyama scheme can be used. It is a numerical method for solving \gls{SDE}s.

For an \gls{SDE} of the form
\begin{align*}
    dS_t = a(S_t)\,dt + b(S_t)\,dW_t,
\end{align*}
the Euler-Maruyama scheme is defined as follows. Let $\hat{S}$ denote the approximate solution and $S$ the exact solution. The recursive formula is given by
\begin{align*}
    \hat{S}(t_{i+1}) = \hat{S}(t_i) + a(\hat{S}(t_i)) \Delta t + b(\hat{S}(t_i)) \sqrt{\Delta t} Z_{i+1},
\end{align*}
where $\Delta t = t_{i+1} - t_i$ and $Z_{i+1}$ is a standard normal random variable. The functions $a$ and $b$ represent the drift and diffusion terms, respectively, as stated by \citet[pp.~339--340]{glasserman2004monte}.

To simulate a stock trajectory governed by a \gls{GBM}, we set $a(S_t) = \mu S_t$ and $b(S_t) = \sigma S_t$. The resulting scheme becomes
\begin{align*}
    \hat{S}(t_{i+1}) = \hat{S}(t_i) + \mu \hat{S}(t_i) \Delta t + \sigma \hat{S}(t_i) \sqrt{\Delta t} Z_{i+1}.
\end{align*}
A stock trajectory can be simulated by iterating this scheme with a small time step $\Delta t$ over a fixed time horizon.

To simulate a pair of dependent stock trajectories, we can use a system of \gls{GBM}s:
\begin{align*}
    dS_t^d = \mu S_t^d \,dt + \sigma S_t^d \,dW_t^d, \quad d = 1, 2,
\end{align*}
where $W_t^1$ and $W_t^2$ are standard one-dimensional Wiener processes with correlation $\rho$, as described by \citet[p.~104]{glasserman2004monte}.

More generally, dependency structures beyond simple correlation can be introduced by using a copula (see \Cref{sec:CopulaTheory}) to generate dependent Wiener processes.

In financial applications, one is often interested in how changes in asset prices affect the value of financial instruments and associated risk metrics. A widely used method is to simulate future asset prices and compute how the instrument's value or risk metric responds. This enables the calculation of risk measures such as \gls{VaR} and \gls{ES}, as well as pricing financial instruments such as options. This approach is commonly referred to as Monte Carlo simulation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Monte Carlo Methods
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Monte Carlo Methods} \label{sec:MonteCarlo}
In many scientific fields, relationships between variables can be described by deterministic functions linking input and output variables. However, in some cases, the input parameters themselves are random. In such situations, \gls{MC} methods can be particularly useful.

\gls{MC} simulation is a technique for modeling events that involve some source of uncertainty. In \gls{MC} methods, a probability distribution is specified for each random input. Random samples are then drawn from these distributions and used as inputs to a deterministic model. This process is repeated many times to produce a range of possible outcomes. The final step involves performing statistical analysis on the simulated outputs—for example, computing the mean, standard deviation, or percentiles, as stated by \citet[pp.~91--92]{Raychaudhuri2008}.

\gls{MC} methods are widely used in finance. One common application is option pricing, where they are used to simulate the future price of an asset under a given model. By running a large number of simulations, a distribution of possible future prices is obtained, from which the expected price or other statistics can be estimated as described by \citet[p.~105]{KellyConall2024CaSf}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% From before reviewing the language
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Mathematical finance}\label{sec:MathematicalFinance}
% In mathematical finance, one is typically interested in the returns of financial assets, over discrete time steps, rather than their price \citet[p.~2]{Danielsson2011}. Let $P_{t_i}$ denote the price at time increment $t_i$, where $t_i$ is usually in daily time increments, but can be any unit of time. 

% \subsubsection{Returns}
% This section will introduce different types of returns, simple and log, as well as their different properties. These properties are for example return aggregation over time, portfolio return calculations, generation of new prices, and the bounds for returns. The reason for introducing different types of returns is to show the connections between financial returns and statistical distributions that in turn connect to the theory of copulas. 

% Firstly we should introduce what financial returns on assets are. The return of a financial asset is the relative price change over a given time interval, often expressed as a percentage \citet[p.~2]{Danielsson2011}. One type of return is simple returns, defined in \Cref{def:simpleReturns}.

% \begin{definition}\label{def:simpleReturns}
%     \textbf{Simple-Returns} \citet[p.~3]{Danielsson2011}
%     A \emph{simple return} is the percentage change in price, over time period $t_i$, indicated by $R_{t_i}$:
%     \begin{align*}
%         R_{t_i} = \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}}.
%     \end{align*}
% \end{definition}

% To aggregate several simple (daily) returns over some time (week) to the return over the whole period (week), one has to construct several change factors that are multiplied together before subtracting one. This aggregation process is described in \citet[p.~3]{Danielsson2011}, where the aggregated return over $n$ periods can be calculated as
% \begin{align*}
%     R_{t_{i}}(n) = (1+R_{t_{i}})(1+R_{t_{i-1}})(1+R_{t_{i-2}})\dots (1+R_{t_{i-n+1}}) -1 = \frac{P_{t_{i}}}{P_{t_{i-n}}}-1.
% \end{align*}

% In many situations, it is necessary to calculate the return of an entire portfolio of assets from its underlying asset returns. For simple returns, this is simply done by calculating a weighted average of the individual asset returns. \citet[p.~3]{Danielsson2011} describes the calculation of the portfolio return $R_{t_i,\mathrm{port}}$ for a portfolio with $K$ different assets as 
% \begin{align*}
%     R_{t_i,\mathrm{port}} = \sum_{k=1}^K w_kR_{t_i,k}.
% \end{align*}

% Many times, it can be useful to simulate new stock prices by using randomly generated returns. For simple returns, new prices can be calculated as
% \begin{align*}
%     P_{t_{i}} = P_{t_{i-1}}(1+R_{t_{i}}).
% \end{align*}

% The space in which realizations of returns can be observed differs for different types of returns. In \Cref{ex:BoundsSimpleReturns} the range for simple returns is derived. 

% \begin{example}\label{ex:BoundsSimpleReturns}
%     To see the bounds for simple returns, we investigate what happens as the stock price moves to zero, corresponding to bankruptcy, and when the stock price moves to infinity. We denote the simple return when the price goes to zero and infinity by $R_t^-$ and $R_t^+$ respectively   
%     \begin{align*}
%         R_{t_i}^- = \lim_{P_{t_i} \to 0} \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}} = \frac{0-P_{t_{i-1}}}{P_{t_{i-1}}} =  -1 \\
%         R_{t_i}^+ =\lim_{P_{t_i} \to \infty} \frac{P_{t_i}-P_{t_{i-1}}}{P_{t_{i-1}}} = \frac{\infty-P_{t_{i-1}}}{P_{t_{i-1}}}=\infty.\\    
%     \end{align*}
% Hence, we conclude that $R_t \in (R_t^-,R_t^+) = [-1,\infty)$. 
% \end{example}


% Continuously compounded returns or so-called logarithmic returns are often used for financial modeling given their desirable properties. A desirable property is that the returns are \emph{symmetric}, so positive and negative returns of the same magnitude cancel each other out \citet[p.~4]{Danielsson2011}. Log returns are defined, as done by \citet[p.~3]{Danielsson2011}, in \Cref{def:logReturns}. 

% \begin{definition}\label{def:logReturns}
%     \textbf{Log-Returns} \\
%     The logarithm of gross return or \emph{log-returns}, indicated by $Y_{t_i}$:
%     \begin{align*}
%         Y_{t_i} = \mathrm{log}(1+R_{t_i}) = \mathrm{log} \left(\frac{P_{t_i}}{P_{t_{i-1}}}\right) = \mathrm{log}(P_{t_{i}}) -\mathrm{log}(P_{t_{i-1}})
%     \end{align*}
% \end{definition}

% Log-returns have the advantage that the multiperiod, $n$ period, returns are just the sum of one period returns \citet[p.~3]{Danielsson2011}, that is 
% \begin{align*}
%     Y_{t_i}(n) = Y_{t_i}+Y_{t_{i-1}} + \dots + Y_{t_{i-n+1}}.
% \end{align*}

 
% As illustrated by \citet[p.~4]{Danielsson2011}, the portfolio return is more complicated to compute for log returns because the relation is not simply a weighted sum
% \begin{align*}
%         Y_{t_i,\mathrm{port}} &= \mathrm{log}\left(\frac{P_{t_i,\mathrm{port}}}{P_{t_{i-1},\mathrm{port}}}\right) \neq  \sum_{k=1}^K w_k\mathrm{log}\left(\frac{P_{t_i,k}}{P_{t_{i-1},k}}\right), \mathrm{where} \;\\
%         P_{t_i,\mathrm{port}} &= \sum_{k=1}^K w_k P_{t_i,k}.
% \end{align*}


% A weighted average is approximately, but not quite correctly, describing the portfolio returns in terms of the individual returns as described by \citet[p.~3]{Danielsson2011},
% \begin{align*}
%     Y_{t_i,\mathrm{port}} \approx \sum_{k=1}^K w_k R_{t_i,k}.
% \end{align*}

% The correct relation between portfolio log returns and its sub-components log returns is given by first converting the log returns to prices, then calculating the portfolio returns before calculating the log return from the portfolio return
% \begin{align*}
%     Y_{t_i,\mathrm{port}} = \mathrm{log} \left( \frac{\sum_{k=1}^K w_k P_{t_i,k}}{\sum_{k=1}^K w_k P_{t_{i-1},k}}\right), \mathrm{where} \; P_{t_i,k} = P_{t_i-1,k}e^{Y_{t_i,k}}.
% \end{align*}
% In the above expression, the nominator represents the new portfolio value while the denominator represents the initial portfolio value. $K\in \mathbb{N}$ is the number of assets in the portfolio and $w_k$ is the weight of the total portfolio in asset $k$. Note that the individual asset prices are updated, using the log return, by themselves before weighing them together as a portfolio value. 

% In many applications, one wants to simulate returns to produce artificial stock price developments. Log returns from stock prices usually seem to be generated from some sort of bell-shaped probability distribution. This makes it convenient becausecause one can use samples from some probability distribution as the log returns when simulating prices for an asset. As an example, the famous Black-Scholes model assumes that stock returns are log normally distributed. That is, the log returns are normally distributed. 

% To obtain the price $P_{t_i}$ at the end of time period $t_i$ using a simulated log return $Y_{t_i}$ for period $t_i$, one can calculate 
% \begin{align*}
%     P_{t_i} = P_{t_{i-1}}e^{Y_{t_i}}. %(own)
% \end{align*}

% The range in which log returns can be observed is, unlike those in the simple return case, unbounded both positively and negatively. 
% \begin{example}
%     To see this we investigate what happens to the returns when the stock price moves to zero, corresponding to bankruptcy, and when the stock price moves to infinity. We denote the log return when the price goes to zero and infinity by $Y_t^-$ and $Y_t^+$ respectively.   
%     \begin{align*}
%         Y_{t_i}^- = \lim_{P_{t_i} \to 0} \mathrm{log} \left( \frac{P_{t_i}}{P_{t_{i-1}}}\right) = \mathrm{log}(0)= -\infty\\
%         Y_{t_i}^+ =\lim_{P_{t_i} \to \infty} \mathrm{log}\left( \frac{P_{t_i}}{P_{t_{i-1}}}\right) = \mathrm{log}(\infty)= \infty\\    
%     \end{align*}
%     Hence, we conclude that $Y_{t_i} \in (Y_{t_i}^-,Y_{t_i}^+) = (-\infty,\infty)$. 
% \end{example}

% To better understand how the different types of returns work, \Cref{ex:returnSymmetry} shows that simple returns are not symmetrical whereas log returns are. 
% \begin{example}\label{ex:returnSymmetry}
%     \textbf{Symmetry of returns} (own example, on the same lines as \citet[p.~4]{Danielsson2011} but not quite)
%     Consider an example of a stock having initial price $P_0 = 100$, price after one day $P_1 = 200$, and price at day two $P_2 = 100$. Let's examine what these price changes do to simple and log returns respectively.
    
%     \textbf{Simple returns}\\
%     The return on the first day is
%     \begin{align*}
%         R_1 = \frac{P_1-P_0}{P_0} = \frac{200-100}{100} = 1 = 100\%.
%     \end{align*}
%     The return on the second day is
%     \begin{align*}
%         R_2 = \frac{P_2-P_1}{P_1} = \frac{100-200}{200} = -\frac{1}{2} = -50\%.
%     \end{align*}    
%     \textbf{Log returns}\\
%     The return on the first day is 
%     \begin{align*}
%        Y_1 = \log \left( \frac{P_1}{P_0}\right) = \log\left(\frac{200}{100}\right)  = \log(2) \approx 69 \%.
%     \end{align*}
%     The return on the second day is
%     \begin{align*}
%         Y_2 = \log\left(\frac{P_2}{P_1}\right) = \log\left(\frac{100}{200}\right)= \log\left(\frac{1}{2}\right) \approx -69\%.
%     \end{align*}
%     We can see that the log returns are symmetrical so that monetary gains and losses of equal magnitude have log returns of equal magnitude. This is in contrast to simple returns where gains and losses are not symmetrical.
% \end{example}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% GBM
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Geometric Brownian motion}
% The symmetrical property of log returns is desirable because it means that the log returns can be modeled using a normal distribution. This is a convenient because the normal distribution has many nice properties and is easy to work with. Log returns are often used in financial modeling, perhaps most notably in the Black-Scholes model, for option pricing, where stock prices are assumed to follow a \gls{GBM} which price is log normally distributed. This is a consequence of the log returns being normally distributed. The \gls{GBM} is a stochastic process that is used to model the evolution of stock prices. The \gls{GBM} is defined by the stochastic differential equation (SDE)
% \begin{align*}
%     dS_t &= \mu S_t dt + \sigma S_t dW_t \\
%     S_0 &= s_0, 
% \end{align*}
% where $S_t$ is the stock price at time $t$, $\mu$ is the drift, $\sigma$ is the volatility, and $W_t$ is a Wiener process \Citet[p.~67]{Bjork2019Edition4} \todo{Find page where GBM defined}. The \gls{GBM} can be solved using the Itô formula, which gives the solution
% \begin{align*}
%     S_t = s_0 \;\mathrm{exp}\left( \left( \mu - \frac{\sigma^2}{2} \right)t + \sigma W_t \right),
% \end{align*}
% \Citet[p.~70]{Bjork2019Edition4}.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% Euler Maruyama
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Euler-Maruyama Scheme}\label{sec:EulerMaruyama}\todo{Change X to S}
% To approximately simulate \gls{SDE}s the Euler-Maruyama scheme can be used. The Euler-Maruyama scheme is a numerical method for solving \gls{SDE}s.

% For an \gls{SDE} of the form
% \begin{align*}
% dS_t = a(S_t)dt + b(S_t)dW_t,
% \end{align*}
% the Euler-Maruyama scheme is defined as follows.
% Let $\hat{S}$ denote the approximate solution to the \gls{SDE} and let $S$ denote the exact solution. The Euler-Maruyama scheme is defined by the following recursive formula
% \begin{align*}
% \hat{S}(t_{i+1}) = \hat{S}(t_i) + a(\hat{S}(t_i))[t_{i+1}-t_i] + b(\hat{S}(t_i)) \sqrt{t_{i+1}-t_i} Z_{i+1},
% \end{align*}
% where $Z_{i+1}$ is a standard normal random variable. The time step $t_{i+1}-t_i$ is the time increment, and $a$ and $b$ are the drift and diffusion functions respectively \Citet[pp.~339-340]{glasserman2004monte}.

% We can use the Euler-Maruyama scheme to simulate a stock trajectory with the \gls{GBM} by setting $a(S_t) = \mu S_t$ and $b(S_t) = \sigma S_t$. The resulting scheme is
% \begin{align*}
% \hat{S}(t_{i+1}) = \hat{S}(t_i) + \mu \hat{S}(t_i)[t_{i+1}-t_i] + \sigma \hat{S}(t_i) \sqrt{t_{i+1}-t_i} Z_{i+1}.
% \end{align*}
% To simulate a stock trajectory, the time increment $t_{i+1}-t_i$ is set to a small value, and the process is iterated for a large number of steps.

% We can simulate a pair of dependent stock trajectories by simulating a system of \gls{GBM}s
% \begin{align*}
% dS_t^d = \mu S_t^d dt + \sigma S_t^d dW_t^d, ; d=1,2,
% \end{align*}
% where $W_t^1$ and $W_t^2$ are standard one dimensional Wiener processes with correlation $\rho$ \Citet[p.~104]{glasserman2004monte}. One can also simulate a system of \gls{GBM}s with a dependence different than correlation. This can be done by using a copula to generate the dependent Weiner processes.

% In financial applications one is often interested in what impact changes in asset prices have on the value of a financial instrument and risk metrics. To do this a widely used method is to simulate the future price of the underlying asset and then calculate how the value of the instrument or metric changes based on the simulated prices. This allows for the calculation of risk metrics such as \gls{VaR} and \gls{ES} as well as the pricing of financial instruments such as options. The method is often referred to as \gls{MC} simulation.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% Euler Maruyama
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Euler-Maruyama Scheme}\label{sec:EulerMaruyama}\todo{Change X to S}
% To approximately simulate \gls{SDE}s the Euler-Maruyama scheme can be used. The Euler-Maruyama scheme is a numerical method for solving \gls{SDE}s. 

% For an \gls{SDE} of the form
% \begin{align*}
%     dX_t = a(X_t)dt + b(X_t)dW_t,
% \end{align*}
% the Euler-Maruyama scheme is defined as follows. 
% Let $\hat{X}$ denote the approximate solution to the \gls{SDE} and let $X$ denote the exact solution. The Euler-Maruyama scheme is defined by the following recursive formula 
% \begin{align*}
%     \hat{X}(t_{i+1}) = \hat{X}(t_i) + a(\hat{X}(t_i))[t_{i+1}-t_i]  + b(\hat{X}(t_i)) \sqrt{t_{i+1}-t_i} Z_{i+1},
% \end{align*}
% where $Z_{i+1}$ is a standard normal random variable. The time step $t_{i+1}-t_i$ is the time increment, and $a$ and $b$ are the drift and diffusion functions respectively \Citet[pp.~339-340]{glasserman2004monte}.

% We can use the Euler-Maruyama scheme to simulate a stock trajectory with the \gls{GBM} by setting $a(S_t) = \mu S_t$ and $b(S_t) = \sigma S_t$. The resulting scheme is
% \begin{align*}
%     \hat{S}(t_{i+1}) = \hat{S}(t_i) + \mu \hat{S}(t_i)[t_{i+1}-t_i]  + \sigma \hat{S}(t_i) \sqrt{t_{i+1}-t_i} Z_{i+1}.
% \end{align*}
% To simulate a stock trajectory, the time increment $t_{i+1}-t_i$ is set to a small value, and the process is iterated for a large number of steps. 

% We can simulate a pair of dependent stock trajectroies by simulating a system of \gls{GBM}s  
% \begin{align*}
%     dS_t^d = \mu S_t^d dt + \sigma S_t^d dW_t^d, \; d=1,2, 
% \end{align*}
% where $W_t^1$ and $W_t^2$ are standard one dimensional Wiener processes with correlation $\rho$ \Citet[p.~104]{glasserman2004monte}. One can also simulate a system of \gls{GBM}s with a dependence different than correlation. This can be done by using a copula to generate the dependent Weiner processes.

% In financial applications one is often interested in what impact changes in asset prices have on the value of a financial instrument and risk metrics. To do this a widely used method is to simulate the future price of the underlying asset and then calculate how the value of the instrument or metric changes based on the simulated prices. This allows for the calculation of risk metrics such as \gls{VaR} and \gls{ES} as well as the pricing of financial instruments such as options. The method is often referred to as \gls{MC} simulation.  


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%% Monte Carlo methods
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Monte Carlo methods} \label{sec:MonteCarlo}
% Many times in different scientific fields, relationships between different variables can be described using deterministic relationships between input variables and output variables. In some situations, these deterministic relationships have random input parameters. In these cases, \gls{MC} methods can be useful. 

% \gls{MC} simulation is a method for simulating events that, due to some source of randomness, are uncertain. In \gls{MC} methods, a statistical distribution is identified for each source of randomness. The method is then to sample random numbers from these distributions to use as input in the deterministic relationship. This gives the outcome for multiple possible scenarios. The final step is to perform some statistical analysis of the generated output values from the functions. This can, for example, be used to calculate the mean, standard deviation, or percentile \Citet[pp.~91-92]{Raychaudhuri2008}. \gls{MC} methods are widely used in finance, for example to price options where they are often used to simulate the future price of an asset, given a model for the asset price. By performing a large number of simulations, one can obtain a distribution of possible future prices from which the price can be estimated \Citet[p.~105]{KellyConall2024CaSf}. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Probability theory
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Probability theory}
% As mentioned above, stock returns are often modeled using some statistical distribution. Statistical distributions are fundamental to the theory of copulas, and we therefore need to define the terminology surrounding distributions more formally. Throughout the following sections, visual illustrations will be used to explain key ideas. Unless otherwise stated, the Gaussian distribution with mean 0 and standard deviation 1 will be used for these illustrations.

% We begin by defining statistical distributions, starting with the \gls{CDF} in one dimension, as shown in \Cref{def:CDF1d}.

% \begin{definition}\label{def:CDF1d} \textbf{Cumulative Distribution Function in one dimension }  \citet[p.~17]{Nelsen2006}\\
%     A \emph{distribution function} or \gls{CDF} is a function $F$ with domain $\bar{R} = [-\infty, \infty]$ such that 
%     \begin{compactenum}
%         \item $F$ is non-decreasing; 
%         \item $F(-\infty)=0$ and $F(\infty)=1$.
%     \end{compactenum}
% \end{definition}

% The value of the \gls{CDF} at a point in its domain $\bar{R}$ can be interpreted as the probability that a realization is less than or equal to that point. Closely related to the \gls{CDF} is the \gls{PDF}, defined in \Cref{def:PDF1d}.

% \begin{definition}\label{def:PDF1d} \textbf{Probability Density Function in one dimension} \citet[pp.~160-161]{DevoreBerk2012}\\
%     Let $X$ be a continuous random variable. Then a \emph{probability distribution} or \gls{PDF} of $X$ is a function $f(x)$ such that for any two numbers $a$ and $b$ with $a \leq  b$,
%         \begin{align*}
%             P(a \leq X \leq b) = \int_a^b f(x)\,dx.
%         \end{align*}
% \end{definition}

% \begin{remark}\label{rem:pdfProperties}
%     For a function to be a valid \gls{PDF}, the following conditions must be satisfied:
%     \begin{align*}
%         f(x) \geq 0 \; \text{for all } x;\\
%         \int_{-\infty}^{\infty} f(x)\,dx = 1.
%     \end{align*}
%     These conditions are implied by \Cref{def:PDF1d} but are explicitly stated here for clarity.
% \end{remark}

% \Cref{fig:PDFandCDF1D} illustrates both a \gls{PDF} (left) and a \gls{CDF} (right) for a standard normally distributed random variable $X$. In the left figure, a histogram of simulated data from the standard normal distribution is shown along with the theoretical density. The \gls{PDF} represents the likelihood of a realization of $X$ falling at a specific point in its domain. The right figure shows the corresponding \gls{CDF}, where each value represents the cumulative probability of falling below that point.

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{3Theory/pictures/CDFandPDF1D.png}
%     \caption{Illustration of a \gls{PDF} (left) and \gls{CDF} (right) for a standard normally distributed random variable $X$.}
%     \label{fig:PDFandCDF1D}
% \end{figure}
% \todo{Make Left Right pictures}

% When dealing with multiple assets, the notion of a \gls{CDF} generalizes to a multivariate \gls{CDF}. To define such a function formally in two dimensions, we first introduce the concept of $H$-volume and the property of being 2-increasing, following \citet[p.~8]{Nelsen2006}, in \Cref{def:H-volume} and \Cref{def:2-Increasing}.

% \begin{definition}\label{def:H-volume} \textbf{H-Volume} \citet[p.~8]{Nelsen2006}\\
%     Let $u$ and $v$ be nonempty subsets of $\bar{R} = [-\infty, \infty]$, and let $H$ be a two-variable real function with domain $\D H = u \times v$. Let $B = [u_1,u_2] \times [v_1,v_2]$ be a rectangle with all vertices in $\D H$. Then the \emph{H-volume} of $B$ is given by
%     \begin{align*}
%         V_H(B) = H(u_2,v_2) - H(u_2,v_1) - H(u_1,v_2) + H(u_1,v_1).
%     \end{align*}
% \end{definition}

% \begin{definition}\label{def:2-Increasing} \textbf{2-Increasing} \citet[p.~8]{Nelsen2006}\\
%      A two-variable real function $H$ is \emph{2-increasing} if $V_H(B) \geq 0$ for all rectangles $B$ whose vertices lie in $\D H$.
% \end{definition}

% \Cref{fig:2-Increasing} illustrates what it means for a function to be 2-increasing (left) and not 2-increasing (right). This property is necessary to define a multivariate \gls{CDF}, as shown in \Cref{def:JointCDF}, following \citet[p.~17]{Nelsen2006}.

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{3Theory/pictures/2increasingAndNot.png}
%     \caption{Illustration of a function that is 2-increasing (left) and a function that is not (right), using the $H$-volume.}
%     \label{fig:2-Increasing}
% \end{figure}
% \todo{Make Left Right pictures}

% \begin{definition}\label{def:JointCDF} \textbf{Joint CDF} \\ 
%     A \emph{joint distribution function} or joint \gls{CDF} is a function $F$ with domain $\bar{R}^2 = [-\infty, \infty]^2$ such that 
%     \begin{compactenum}
%         \item $F$ is 2-increasing;
%         \item $F(x_1,-\infty) = F(-\infty, x_2) = 0$, and $F(\infty,\infty) = 1$.
%     \end{compactenum}
% \end{definition}

% As in the univariate case, the value of the joint \gls{CDF} at any point in $\D X \times \D Y \in \bar{R}^2$ represents the probability of both variables falling below that point simultaneously.

% A two-dimensional \gls{PDF} is defined analogously, as described by \citet[p.~235]{DevoreBerk2012}, in \Cref{def:JointPDF}.

% \begin{definition}\label{def:JointPDF} \textbf{Joint PDF} \todo{Change X,Y to $X_1$, $X_2$?}\\
%     Let $X$ and $Y$ be continuous random variables. Then $f(x, y)$ is the \emph{joint} \gls{PDF} for $X$ and $Y$ if for any two-dimensional set $A$,
%     \begin{align*}
%         P[(X,Y) \in A] =  \iint_A f(x,y)\,dx\,dy.
%     \end{align*}
    
%     In particular, if $A = \{(x,y) : a \leq x \leq b, \, c \leq y \leq d\}$, then
%     \begin{align*}
%         P[(X,Y) \in A] = P(a \leq X \leq b, \, c \leq Y \leq d) = \int_a^b\!\!\!\int_c^d f(x,y)\,dy\,dx.
%     \end{align*}
% \end{definition}

% \begin{remark}
%     As in the univariate case, the joint \gls{PDF} $f(x,y)$ must satisfy:
%     \begin{align*}
%         &f(x,y) \geq 0, \quad \text{and} \\
%         &\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x,y)\,dy\,dx = 1.
%     \end{align*}
% \end{remark}

% The joint \gls{PDF} and \gls{CDF} are visualized in \Cref{fig:JointCDFandPDF} to support intuition. The left figure shows a joint \gls{PDF} for $X = (X_1, X_2)$ from a standard normal distribution with zero correlation. The right figure shows the corresponding joint \gls{CDF}.

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{3Theory/pictures/MultivariatePDFandCDF.png}
%     \caption{Illustration of a joint \gls{PDF} (left) and joint \gls{CDF} (right) for a bivariate standard normal random variable $X = (X_1, X_2)$.}
%     \label{fig:JointCDFandPDF}
% \end{figure}
% \todo{Make Left Right pictures}



% \subsection{Maximum Likelihood}

% Another important concept that will be used when fitting distributions and copulas is the \gls{MLE} method. \gls{MLE} is a method for estimating the parameters of a statistical model by finding the parameter values that maximize the likelihood function, given the observed data.

% Let $\theta$ be a vector of parameters, and let $X = (X_1, X_2, \dots, X_n)$ be a sample of $n$ independent observations from a distribution with density function $f(x;\theta)$. Then the likelihood function is defined as
% \begin{align*}
%     L(\theta; x_1, x_2, \dots, x_n) = \prod_{i=1}^{n} f(x_i; \theta).
% \end{align*}
% It is often convenient to work with the natural logarithm of the likelihood function, known as the \emph{log-likelihood}:
% \begin{align*}
%     \ell(\theta; x_1, x_2, \dots, x_n) = \log L(\theta; x_1, x_2, \dots, x_n) = \sum_{i=1}^{n} \log f(x_i; \theta).
% \end{align*}
% The maximum likelihood estimator $\hat{\theta}$ is the value of $\theta$ that maximizes the log-likelihood function:
% \begin{align*}
%     \hat{\theta} = \arg\max_{\theta} \ell(\theta; x_1, x_2, \dots, x_n).
% \end{align*}
% MLE will be used throughout this work to estimate the parameters of various distributions, including marginal distributions and copula parameters.

% \subsection{Summary}
% This subsection has laid the groundwork for understanding copulas by introducing key concepts in probability theory. We have covered univariate and multivariate cumulative distribution functions (CDFs), probability density functions (PDFs), and the notion of 2-increasing functions necessary for defining joint CDFs. We also introduced tools such as the probability integral transform (PIT) and the inverse transform method (ITM), both essential for understanding and constructing copulas.

% Furthermore, we defined marginal distributions as projections of joint distributions onto single dimensions and explained how the PIT can be applied to data, transforming it into a uniform distribution on the $[0,1]$ interval. This transformation is a crucial step before copulas can be applied, as copulas operate on data in the probability space.

% Lastly, we introduced the method of maximum likelihood estimation (MLE), which will be the primary method for fitting models to data in the following sections. With these tools in hand, we are now ready to explore the theory and applications of copulas.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% From before reviewing the language
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Probability Theory}\label{sec:ProbabilityTheory}
As mentioned above, stock returns are often modeled using some statistical distribution. Statistical distributions are fundamental to the theory of copulas and therefore we need to define the terminology around distributions more formally. Throughout the upcoming sections, illustrations will be made to explain the ideas visually. Unless otherwise stated the Gaussian distribution, with mean 0 and standard deviation 1, will be used for these illustrations.

First, we need to define what statistical distributions are, beginning with \gls{CDF} in one dimension defined in \Cref{def:CDF1d} as done by \Citet[p.~17]{Nelsen2006}.
\begin{definition}\label{def:CDF1d} \textbf{CDF in one dimension }\\
    A \emph{distribution function} or \gls{CDF} is a function $F$ with domain $\bar{R} = [-\infty, \infty]$ such that 
    \begin{compactenum}
        \item $F$ is nondecreasing; 
        \item $F(-\infty)=0$ and $F(\infty)=1$.
    \end{compactenum}
\end{definition}

One can think of the \gls{CDF} at each point on its domain $\bar{R}$ as the probability of a realization being below that point. Tied to the \gls{CDF} is the \gls{PDF}, which is defined in \Cref{def:PDF1d} as done by \Citet[pp.~160-161]{DevoreBerk2012}.

\begin{definition}\label{def:PDF1d} \textbf{PDF in one dimension} \\
    Let $X$ be a random variable. Then a \emph{probability distribution} or \gls{PDF} of $X$ is a function $f(x)$ where $x \in \mathbb{R}$ such that for any two numbers $a$ and $b$ with $a \leq b$,
        \begin{align*}
            P(a \leq X \leq b) = \int_a^bf(x)dx.\\
        \end{align*}
\end{definition}
\begin{remark}\label{rem:pdfProperties}
    Note that for a function to be a valid \gls{PDF}, the following conditions must be satisfied: 
    \begin{align*}
        f(x) \geq 0 \; \mathrm{ for\; all \;} x \in \mathbb{R};\\
        \int_{-\infty}^{\infty}f(x)dx = 1. 
    \end{align*}
    These are implied by \Cref{def:PDF1d} but are explicitly stated here for clarity. 
\end{remark}


\Cref{fig:PDFandCDF1D} illustrates both a \gls{PDF} (left) and \gls{CDF} (right) for a random variable $X$, being standard normally distributed. In the left figure, we can see a histogram in blue of simulated data generated from the standard normal distribution as well as the theoretical normal distribution illustrated by the black line. The \gls{PDF} shows the likelihood of a realization of the $X$ to end up at each point in the domain of $X$. The right picture shows the \gls{CDF} in red corresponding to the \gls{PDF}, its function value in each point is defined as the probability of ending up below that point on the domain of $X$.

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/PDFIllustrated.png}
        \caption{Illustration of a \gls{PDF} for a standard normally distributed random variable.}
        \label{fig:PDF1d}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/CDFIllustrated.png}
        \caption{Illustration of a \gls{CDF} for a standard normally distributed random variable.}
        \label{fig:CDF1d}
    \end{subfigure}
    \caption{Illustration of a \gls{PDF} (left) and \gls{CDF} (right) for a random variable $X$, being standard normally distributed, in one dimension.}
    \label{fig:PDFandCDF1D}
\end{figure}


When dealing with multiple assets the notion of a \gls{CDF} generalizes to a multivariate \gls{CDF}. To define a multivariate \gls{CDF} formally in two dimensions we will need to define the $H$-volume of a function in two dimensions and what the meaning of a function being 2-increasing is. This is done in the same manner as in \Citet[p.~8]{Nelsen2006} in \Cref{def:H-volume} and \Cref{def:2-Increasing}.

\begin{definition}\label{def:H-volume} \textbf{H-Volume} \\
    Let $u$ and $v$ be nonempty subsets of $\bar{R} = [-\infty, \infty]$, let $H$ be a function such that $H:\mathbb{R}\times\mathbb{R}\to \mathbb{R}$, and let $\D H = u\times v$. Let $B = [u_1,u_2]\times[v_1,v_2]$  be a rectangle all of whose vertices are in $\D H$. Then
    the \emph{H-volume} of $B$ is given by
    \begin{align}\label{eq:H-volume}
        V_H(B) = H(u_2,v_2) - H(u_2,v_1) - H(u_1,v_2) + H(u_1,v_1).
    \end{align}
\end{definition}

\begin{definition}\label{def:2-Increasing} \textbf{2-increasing} \\
     A function $H:\mathbb{R}\times\mathbb{R}\to \mathbb{R}$ is \emph{2-increasing} if its $H$-volume $V_H(B)\geq0$, for all rectangles $B$ whose vertices lie in $\D H$.
\end{definition}

The notion of a 2-increasing function is illustrated in \Cref{fig:2-Increasing} where the surface is a function of two variables, the red dots represent the vertices of the rectangle $B$ in \Cref{def:H-volume}. In the figure, the left picture shows a function that is 2-increasing meaning that it is increasing in both directions. This can be imagined by evaluating \Cref{eq:H-volume} as being larger than zero using the points as vertices of $B$. The right picture illustrates when a function is not 2-increasing as the function is decreasing from $(u_2,v_1)$ to $(u_2,v_2)$. Also, if evaluating \Cref{eq:H-volume} we would find that the $H$-volume is negative, showing that the function is not 2-increasing. This property is needed to define a \gls{CDF} in several dimensions, as done by \Citet[p.~17]{Nelsen2006}, in \Cref{def:JointCDF}. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/2Increasing.png}
        \caption{Illustration of a 2-increasing function.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/Not2increasing.png}
        \caption{Illustration of a function that is not 2-increasing.}
    \end{subfigure}
    \caption{Illustration of what it means for a function to be, and not to be, 2-increasing using the definition of the $H$-volume.}
    \label{fig:2-Increasing}
\end{figure}


\begin{definition}\label{def:JointCDF} \textbf{Joint CDF} \\
    A \emph{joint distribution function} or joint \gls{CDF} is a function $F$ with domain $\bar{R}^2 = [-\infty, \infty]^2$ such that 
    \begin{compactenum}
        \item $F$ is 2-increasing; 
        \item $F(x_1,-\infty)= F(-\infty, x_2) = 0$, and $F(\infty,\infty)=1$.
    \end{compactenum}
\end{definition}

As in the univariate case the function value of the joint \gls{CDF} at any point in $\D X\times \D Y \in\bar{R}^2$ is the probability of being below that point. In the two-dimensional setting, it is the probability of a point ending up below the point in both dimensions simultaneously. 

We can also define a \gls{PDF} in two dimensions as done by \Citet[p.~235]{DevoreBerk2012} in \Cref{def:JointPDF}.

\begin{definition}\label{def:JointPDF} \textbf{Joint PDF}\\
    Let $X$ and $Y$ be random variables. Then $f(x,y)$ where $f:\mathbb{R}\times\mathbb{R}\to \mathbb{R}_+$ is the \emph{joint} \gls{PDF} for $X$ and $Y$ if for any two-dimensional set $A$ 
    \begin{align*}
        P[(X,Y) \in A] =  \iint_A f(x,y)dxdy.
    \end{align*}
    
    In particular, if $A$ is the two-dimensional rectangle $\{(x,y) : a\leq x \leq b, c\leq y \ \leq d\}, $ then
    \begin{align*}
        P[(X,Y) \in A] = P(a\leq X \leq b, c \leq Y \leq d) =\int_a^b\!\!\!\int_c^d f(x,y)dxdy.
    \end{align*}
\end{definition}

\begin{remark}
    As seen in the univariate case, the same applies to the bivariate case. To be a candidate to be a joint \gls{PDF} $f(x,y)$ must satisfy 
    \begin{align*}
        &f(x,y) \geq 0, \;\mathrm{and} \\
        &\int_{-\infty}^{\infty}\!\int_{-\infty}^{\infty}f(x,y)dxdy=1.
    \end{align*}
    For the purposes of this work, we will be focus on continuous random variables.
\end{remark}


Analogously to the univariate setting, the joint \gls{PDF} and \gls{CDF} are illustrated to give a visual understanding. In \Cref{fig:JointCDFandPDF} the left picture shows a joint \gls{PDF} for the random variable $X = (X_1, X_2)$, being standard normally distributed with zero correlation. In the right picture, the joint \gls{CDF} is displayed. 

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{3Theory/pictures/MultivariatePDFandCDF.png}
%     \caption{Illustration of a \gls{PDF} (left) and \gls{CDF} (right) for a two dimensional random variable $X = (X_1,X_2)$, being standard normally distributed.}
%     \label{fig:JointCDFandPDF}
% \end{figure}
% \todo{Make Left Right pictures}

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/BivariatePDF.png}
        \caption{Illustration of a bivariate \gls{PDF} for a standard normally distributed random variable.}
        \label{fig:PDF2d}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/BivariateCDF.png}
        \caption{Illustration of a bivariate \gls{CDF} for a standard normally distributed random variable.}
        \label{fig:CDF2d}
    \end{subfigure}
    \caption{Illustration of a \gls{PDF} and \gls{CDF} for a random variable $X$, being standard normally distributed, in two dimensions.}
    \label{fig:JointCDFandPDF}
\end{figure}


The \gls{PIT} refers to transforming a continuous random variable to a uniformly distributed random variable. 
This maps the domain of a continuous one-dimensional random variable through its \gls{CDF} to the $[0,1]$ space, which may in the sequel be referred to as \emph{probability space}. This transformation will be central when defining copulas and is introduced in \Cref{the:PIT} as done by \Citet[p.~27]{Danielsson2011}. 

\begin{theorem}\label{the:PIT} \textbf{Probability integral transform} \\
    Let $X$ be a continuous random variable with distribution function $F$. Define a new random variable $U = F(X)$, then $U \sim \mathrm{unif}(0,1)$. 
\end{theorem}

The probability integral transform is illustrated in \Cref{fig:PIT} where the red line is a \gls{CDF}, the dotted lines show the path by which three exemplifying data points are being mapped from the real line to probability space. The arrows in the figure illustrate the direction of how the data points are being mapped. We can think of the \gls{PIT} as a method of mapping all observed data points on $\D X$ to probability space.

Deeply connected to the \gls{PIT} is the \gls{ITM}, which is a method of generating random numbers from a given distribution. The method is based on the \gls{PIT} and works as defined in \Cref{def:InverseTransformMethod}, as done by \Citet[p.~54]{glasserman2004monte}.
\begin{definition}\label{def:InverseTransformMethod}
    \textbf{Inverse transform method} \\
    The \emph{inverse transform method} is a method of generating random numbers from a given distribution.
    \begin{compactenum}
        \item Generate random numbers $U \sim \mathrm{Unif}(0,1)$;
        \item Insert the random numbers in the inverse \gls{CDF} of the desired distribution $F$ such that $X = F^{-1}(U)$.
    \end{compactenum}
    The random variable $X$ will then be distributed according to the desired distribution. That is $P(X\leq x) = F(x)$ for all $x$. 
\end{definition}

\begin{remark}
    Note that $F^{-1}$ in \Cref{def:InverseTransformMethod} is the inverse of the \gls{CDF} $F$ if $F$ is strictly increasing. If it is not, $F^{-1}$ denotes the quasi inverse of $F$. The quasi inverse is defined as
    \begin{align*}
        F^{-1}(u) = \inf\{x : F(x) \geq u\}.
    \end{align*}
    In simple terms, this means that if the \gls{CDF} is flat over an interval, the inverse will return the leftmost point of that interval. This is important to note as it can lead to multiple values of $X$ being generated from the same value of $U$.
\end{remark}

The inverse transform method is illustrated in \Cref{fig:ITM} and can be seen as performing the \gls{PIT} in reverse. In the figure the red line is the inverse \gls{CDF} from which the sample is desired to be. The dotted lines represent the random numbers generated from the uniform distribution. The random numbers are then inserted into the inverse \gls{CDF} to obtain the desired sample.

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.471\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/ProbabilityIntegralTransform.png}
        \caption{How the \gls{PIT} is used to transform realizations of a random variable $X$ having distribution function $F$ into a uniformly distributed random variable $U = F(X)$.}
        \label{fig:PIT}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/InverseTransformMethod.png}
        \caption{How the \gls{ITM} is used to generate random numbers from a given distribution given sampled points from a uniform distribution.}
        \label{fig:ITM}
    \end{subfigure}
    \caption{Probability Integral Transform and Inverse Transform Method.}
    \label{fig:TransformMethods}
\end{figure}




Another important notion is that of a marginal distribution of a joint distribution, which can be thought of as the distribution if only considering one of the dimensions that the joint distribution is made up of. The marginal \gls{CDF} and \gls{PDF} are defined in \Cref{def:MarginalCDF} and \Cref{def:MarginalPDF} respectively, in the same way as in \citet[p.~81]{evans2004probability} and \citet[p.~34]{wasserman2010statistics} respectively. 

\begin{definition}\label{def:MarginalCDF}
    \textbf{Marginal \gls{CDF}} 
    Let $X$and $Y$ be two random variables having joint \gls{CDF} $F_{X,Y}$, then the \gls{CDF} $F_X$ of $X$ can be obtained from $F_{X,Y}$ because
    \begin{align*}
        F_X(x) =P(X\leq x)
        =P(X\leq x,Y \leq \infty)
        =\lim_{y\to\infty} F_{X,Y}(x,y).
    \end{align*}
    $F_X$ is called the \emph{marginal distribution function} or marginal \gls{CDF} of $X$. The marginal distribution $F_Y$ can be obtained similarly. 
\end{definition}

\begin{definition}\label{def:MarginalPDF}
    \textbf{Marginal \gls{PDF}}
    For a continuous random variable, with domain $\mathrm{Dom}X\times \mathrm{Dom}Y$ $f_{X,Y}$, having joint \gls{PDF} $f_{X,Y}$, the \emph{marginal density function} or marginal \gls{PDF} of $X$ is given by
    \begin{align*}
        f_X(x) = \int_{-\infty}^\infty f_{X,Y}(x,y)dy.
    \end{align*}
    The marginal density $f_Y$ can be obtained similarly. 
\end{definition}

In \Cref{fig:MarginalCDF} the notion of a marginal distribution is visualized. In the left figure, a joint \gls{CDF} is shown to connect to the prior explanation of a \gls{CDF}. If the distribution is rotated to show it straight from one direction, as shown in the right figure, we can see the marginal distribution. In this case, it is the marginal distribution of $X_2$ that is displayed in red. This figure is of course simplified as it would not be plausible to view the limit when $X_1 \to \infty$.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/BivariateCDF.png}
        \caption{How the \gls{PIT} is used to transform realizations of a random variable $X$ having distribution function $F$ into a uniformly distributed random variable $U = F(X)$.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/MarginalIllustrated.png}
        \caption{Illustration of what the marginal \gls{CDF} looks like for a bivariate normal distribution.}
    \end{subfigure}
    \caption{Marginal \gls{CDF} of a bivariate normal distribution.}
    \label{fig:MarginalCDF}
\end{figure}

To conclude this subsection, we will show how the \gls{PIT} is utilized to transform data to the probability space and explain how it sets the stage for copulas. \Cref{fig:PITonData} illustrates how the \gls{PIT} is used to transform two-dimensional data into the two-dimensional probability space, by transforming the data through each of the marginal distributions separately. This is done for standard normally distributed data with and without correlation in \Cref{fig:CorrelatedScatter} and \Cref{fig:UncorrelatedScatter} respectively, to highlight the differences in the distribution of points in the probability space when dependence is present and not in \Cref{fig:CorrelatedUniformScatter}, and \Cref{fig:UncorrelatedUniformScatter} respectively. In the upper two figures we see the scatter plot of the data in the original space, along with histograms showing the marginal distributions of the data. The lower two figures show the scatter plot of the data in the probability space after applying the \gls{PIT} to each dimension separately. The histograms in the lower figures show that the data is uniformly distributed in the $[0,1]$-domain, as expected from the \gls{PIT}.

\begin{figure}
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/IndependentRet.png}
        \subcaption{ Uncorrelated data from a bivariate standard normal distribution.}
        \label{fig:UncorrelatedScatter}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/GaussianRetScatter.png}
        \subcaption{Correlated data from a bivariate standard normal distribution.}
        \label{fig:CorrelatedScatter}
    \end{minipage}
    \vfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/IndependentProbSpace.png}
        \subcaption{Data in the probability space after applying the \gls{PIT} to uncorrelated normally distributed data.}
        \label{fig:UncorrelatedUniformScatter}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/GaussianProbScatter.png}
        \subcaption{Data in the probability space after applying the \gls{PIT} to correlated normally distributed data.}
        \label{fig:CorrelatedUniformScatter}
    \end{minipage}
    \caption{Illustration of how the \gls{PIT} is used to transform two-dimensional data into the $[0,1]$-domain by considering the marginal distribution of each dimension separately.}
    \label{fig:PITonData}
\end{figure}

Before introducing copulas in the next section we can simply describe the setting for copulas as \gls{CDF} of the data after having transformed it into the probability space using the \gls{PIT}. Relating to \Cref{fig:PITonData} we the copula is the \gls{CDF} of the data in \Cref{fig:UncorrelatedUniformScatter} or \Cref{fig:CorrelatedUniformScatter}.

Some copulas are fitted using \gls{MLE} which is a method of estimating the parameters of a statistical model by maximizing the likelihood. The \gls{MLE} method is defined the appendix in \Cref{sec:MLE}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Copula theory
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Copula Theory}\label{sec:CopulaTheory}
Now that we have a fundamental understanding of some probability theory we can introduce copulas. \Cref{sec:DefiningCopulas} will provide the necessary definitions and theorems to understand what a copula is. \Cref{sec:NeedForCopulas} will explain why we need copulas and how they can be used to model the dependence structure of random variables. \Cref{sec:CopulaUseCase} will provide a brief overview of how copulas can be used in practice.

\subsubsection{Defining Copulas}\label{sec:DefiningCopulas}
To explain copulas we will need to define what it means for a function to be grounded, in \Cref{def:grounded}, and what it means to have margins, in \Cref{def:margins}, defined as in \Citet[p.~9]{Nelsen2006}.

\begin{definition}\label{def:grounded}\textbf{Grounded} \\
    Consider a function on the domain $S_1\times S_2$ where $S_1$ and $S_2$ have the smallest elements $a_1$ and $a_2$ respectively. A function $H$ from $S_1\times S_2$ into $\mathbf{R}$ is \emph{grounded} if $H(x,a_2)= H(a_1,y) = 0 \;\mathrm{for \;all\;} (x,y) \in S_1\times S_2.$
\end{definition}

\begin{definition}\label{def:margins}
    \textbf{Margins}\\
    Consider a function on the domain $S_1\times S_2$ where $S_1$ and $S_2$ have the largest elements $b_1$ and $b_2$ respectively. A function $H$ from $S_1\times S_2$ into $\mathbf{R}$ has \emph{margins} $F$ and $G$ given by
    \begin{align*}
        \D F = S_1, \;\mathrm{and }\; F(x) = H(x,b_2) \;\mathrm{for \;all\;} x \in S_1\\
        \D G = S_2, \;\mathrm{and }\; G(x) = H(b_1,y) \;\mathrm{for \;all\;} y \in S_2.
    \end{align*}
\end{definition}

\Cref{fig:GroundedAndMargins} illustrates what \Cref{def:grounded} and \Cref{def:margins} means when $S_1$ and $S_2$ are both the $[0,1]$-interval. The blue points show what it means to be grounded as described in \Cref{def:grounded} and the red points show what it means to have margins as defined in \Cref{def:margins}. What this means is that a function over $S_1\times S_2$ being grounded and having margins must have function values equal to the shown points. 

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{3Theory/pictures/CopulaBoundaries.png}
    \caption{Illustration showing what it means for a function to be grounded and to have margins.}
    \label{fig:GroundedAndMargins}
\end{figure}

Now we can formally define what a copula is. This is done as in \Citet[p.~10]{Nelsen2006} in \Cref{def:copula}.
\begin{definition}\label{def:copula}
            \textbf{Copula in two dimensions}\\
            Equivalently, a copula is a function $C$ from $\mathrm{I}^2=[0,1]^2$ to $\mathrm{I} = [0,1]$ with the following properties:
            \begin{enumerate}
                \item For every $u, v \in \mathrm{I}$,
                \begin{align*}
                    C(u,0) &= C(0,v) = 0,\\
                    C(u,1) &= u, \; \mathrm{and } \; C(1,v) = v;
                \end{align*}
                \item For every $u_1, u_2, v_1, v_2 \in \mathrm{I}$ such that $u_1 \leq u_2$ and $v_1 \leq v_2$,
                \begin{align*}
                    C(u_2,v_2) - C(u_2,v_1) - C(u_1,v_2) + C(u_1,v_1) \geq 0.
                \end{align*}
            \end{enumerate}
\end{definition}

So, to describe what a copula is in simpler terms, it is a \gls{CDF} capturing the dependence between points on the probability space, obtained by performing the \gls{PIT} on each marginal distribution. 

A fundamental theorem connected to copulas is described in \Cref{the:Sklars}, as formulated by \Citet[p.~18]{Nelsen2006}. 
\begin{theorem}\label{the:Sklars}
        \textbf{Sklar's theorem} \\
        Let $H$ be a joint distribution function with margins $F$ and $G$ then there exists a copula $C$ such that for all $x,y \in \bar{\mathbf{R}} = \left[-\infty, \infty \right]$, 
        \begin{align}
            H(x,y) = C(F(x), G(y)). \label{eq:Sklar}
        \end{align}
        If $F$ and $G$ are continuous, then $C$ is unique; otherwise, $C$ is uniquely determined on $\mathrm{Ran}(F)\times\mathrm{Ran}(G)$. Conversely, if $C$ is a copula and $F$ and $G$ are distribution functions, then the function $H$ is a joint distribution function with margins $F$ and $G$.
\end{theorem}

\Cref{fig:CDFtoCopula} illustrates the correspondence, given in \Cref{eq:Sklar}, between a bivariate normal \gls{CDF} and its corresponding copula function. The copula has the same function value as the \gls{CDF} in each point where the mapping of points in $X_1\times X_2$ to $[0,1]\times[0,1]$ is done by the \gls{PIT}. The left picture shows the joint \gls{CDF} on the $\bar{R}^2$ domain. The right picture shows the corresponding copula function defined on the unit square. Hence, the difference between the joint \gls{CDF} and the copula is that the copula only exists on the unit square. 

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/BivariateCDF.png}
        \caption{Marginal \gls{CDF} of a bivariate normal distribution.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/BivariateCopula.png}
        \caption{Illustration of the copula corresponding to the distribution.}
    \end{subfigure}
    \caption{Illustration of how copulas are connected to the joint distribution function.}
    \label{fig:CDFtoCopula}
\end{figure}


Sometimes it is more convenient to write the \Cref{eq:Sklar} in terms of the marginal probabilities $u_i$ rather than the marginal distributions $x_i$. It can be done by utilizing that $F_i(x_i) = u_i$ and $F_i^{-1}(u_i)= x_i$ so that 
\begin{align*}
    H(F_1^{-1}(u_1),F_2^{-1}(u_2))=H(x_1,x_2) = C(F_1(x_1), F_2(x_2))= C(u_1, u_2).
\end{align*}

Another important result for copulas is that they are invariant under strictly increasing transformations, the meaning of this is presented in \Cref{the:TranslationInvariance}, as done by \citet[p.~25]{Nelsen2006}.

\begin{theorem}\label{the:TranslationInvariance}
        \textbf{Invariance under strictly increasing transformations}\\
        Let $X$ and $Y$ be continuous random variables with copula $C_{X, Y}$. If $\alpha$ and $\beta$ are strictly increasing on $Ran(X)$ and $Ran(Y)$, respectively, then $C_{\alpha(X),\beta(Y)}  = C_{X,Y}$. Thus $C_{X, Y}$ is invariant under strictly increasing transformations of $X$ and $Y$.
\end{theorem}

From the requirements specified in \Cref{def:copula} one can obtain bounds for how copulas can look. These bounds are defined as by \Citet[p.~11]{Nelsen2006} in \Cref{thm:FrechetBounds}.
    
\begin{theorem}\label{thm:FrechetBounds}
    \textbf{Fréchet-Hoeffding bounds} \\
    Consider a copula $C(\mathbf{u}) = C(u_1,u_2)$. Then $C$ is bounded by
    \begin{align*}
        L(u_1,u_2) &\leq C(u_1,u_2) \leq U(u_1,u_2),\; \mathrm{ where}\\
        L(u_1,u_2) &= (u_1+u_2-1)^+\\
        U(u_1,u_2) &= \mathrm{min}(u_1,u_2).
    \end{align*}
    $L$ and $U$ are referred to as the Fréchet-Hoeffding lower and upper bounds respectively. 
\end{theorem}

Another important copula is the \emph{independence copula} or product copula corresponding to when the two marginal distributions are independent. The independence copula is defined by \Citet[p.~7]{Schmidt2006} as
\begin{align*}
    \Pi(u_1,u_2) = u_1u_2.
\end{align*}

\Cref{fig:FrechetBounds} illustrates the upper (left) and lower (middle) bounds for copulas. We can think of it as if these bounds define a space where all copulas must be confined. One such copula is the independence copula (right) corresponding to the case when random variables are independent. 

\begin{figure}
    \centering
    \includegraphics[width=1.\linewidth]{3Theory/pictures/FrechetBounds.png}
    \caption{Illustration of the Fréchet-Hoeffding upper $U$ (left), and lower $L$ (middle) bounds, as well as the independence copula $\Pi$ (right).}
    \label{fig:FrechetBounds}
\end{figure}

We have now discussed what copula functions are and arrived at that copulas are \gls{CDF}s on the unit square. When fitting copulas to data using \gls{MLE} it is often useful to have the copula \gls{PDF}. Deriving the copula \gls{PDF} is not as straightforward as one might initially think. Therefore we will derive the copula \gls{PDF} in the general case. Let $C(u_1,u_2)$ be the copula \gls{CDF} you want to derive the \gls{PDF} for. The copula \gls{PDF} is defined as the second derivative of the copula \gls{CDF} with respect to $u_1$ and $u_2$.
\begin{align*}
    c(u_1,u_2) =& \frac{\partial^2C(u_1,u_2)}{\partial u_1\partial u_2} = 
    \frac{\partial^2F(F_1^{-1}(u_1),F_2^{-1}(u_2))}{\partial u_1\partial u_2}\\
    =&  f(F_1^{-1}(u_1),F_2^{-1}(u_2)) \frac{d}{du_1} F_1^{-1}(u_1)  \frac{d}{du_2} F_2^{-1}(u_2),
\end{align*}
where, as per the inverse function rule, the derivative of the inverse function is given by
\begin{align*}
    \frac{d}{du_i} F_i^{-1}(u_i) = \frac{1}{f_i(F_i^{-1}(u_i))}.
\end{align*}
In the above equations, $F_i$ is the $i$-th marginal distribution function, \gls{CDF}, and $f_i$ is the marginal density function \gls{PDF}, $F$ is the joint distribution function.   

Hence the copula \gls{PDF} can be written as 
\begin{align*}
    c(u_1,u_2) &= f(F_1^{-1}(u_1),F_2^{-1}(u_2)) \frac{1}{f_1(F_1^{-1}(u_1))}\frac{1}{f_2(F_2^{-1}(u_2))}. 
\end{align*}

% It can also be useful to write the copula in terms of data points that in the return space as this is typically where the data is observed
% \begin{align*}
%     c(u_1,u_2) &= f(F_1^{-1}(u_1),F_2^{-1}(u_2)) \frac{1}{f_1(F_1^{-1}(u_1))}\frac{1}{f_2(F_2^{-1}(u_2))},
% \end{align*}
% where $x_i = F_i^{-1}(u_i)$ and $f_i$ is the marginal \gls{PDF} of the i:th marginal distribution. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% The need for copulas
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Usefulness of Copulas}\label{sec:NeedForCopulas}

The following examples are to illustrate how correlation can fail to capture the true dependence between random variables. The first example shows how correlation fails to capture the dependence between two random variables that are dependent but uncorrelated and is inspired by \Citet[p.~21]{Danielsson2011}. The second example shows how correlation underestimates the true dependence between two random variables that are dependent but not both normally distributed. This is to illustrate how correlation falls short as a measure of dependence, and that copulas can be a better alternative when estimating dependence between random variables. \Cref{ex:CorrelationUnderestimates} is provided with full derivations in \Cref{sec:CorrelationUnderestimatesAppendix} in the appendix, \Cref{sec:CorrelationUnderestimates}.

\begin{example}\label{ex:CorrelationFail}
    \textbf{Dependence is not always captured by correlation}\\
    Let $X$ be a random variable such that, $X \sim N(0,1)$. Obviously, $X$ and $X^2$ are dependent. The covariance, $\mathrm{Cov}(X,X^2)$ is 
    \begin{align*}
        \mathrm{Cov}(X,X^2) &= E \left[  (X-E\left[  X \right])(X^2-E\left[  X^2 \right])  \right]\\
         &=  E \left[  (X)(X^2-1)  \right]\\
         &= E \left[  X^3  \right] - E \left[  X  \right]\\
         &= 0-0 = 0 .
    \end{align*}
    Since $\mathrm{Cov}(X,X^2) = \rho_{X,X^2}\sigma_{X}\sigma_{X^2} = \rho_{X,X^2}$ this shows that $\rho_{X,X^2} = 0.$
    Hence, $X$ and $X^2$ are dependent but uncorrelated. This shows how correlation falls short as a method of capturing non-linear dependence.
    %\todo{Maybe illustrate how this problem is solved using a copula(example of how in Brigo)}
    
    % Using a copula instead we get
    % \begin{align*}
    % F_{X^2}(X^2) &= P(X^2 \leq x^2)\\
    % &= P(\sqrt{X^2} \leq \sqrt{x^2})\\
    % &= P(|X| \leq |x| )\\    
    % &=P(X\leq x) = U2 \neq U1.\\
    % \end{align*}

    % Since the absolute value signs information is lost and hence 
    % \begin{align*}
    %     P(U_1\leq u1, U_2\leq u2) = P(U_1\leq u1, U_1\leq u2) = \min(u_1,u_2).
    % \end{align*}
    
\end{example}

\begin{example}\label{ex:CorrelationUnderestimates}
    \textbf{Correlation underestimates the true dependence} \\
    Let $X$ be a random variable such that, $X \sim N(0,1)$. Obviously, $X$ and $e^X$ are dependent. The covariance, $\mathrm{Cov}(X,e^X)$ is
    \begin{align*}
        \mathrm{Cov}(X,e^X) &= E \left[  (X-E\left[  X \right])(e^X-E\left[  e^X \right])  \right]\\
        %  &=  E \left[  X(e^X-E\left[  e^X \right]) \right]\\
        %  &= E \left[  Xe^X  \right] - E \left[  X E \left[  e^X \right] \right]\\
        %  &= E \left[  Xe^X  \right]\\
        %  &= \int_{-\infty}^\infty xe^x \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}} dx\\ %by definition of expectation for Cont. rand. var. 
        %  &=  \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} x  e^{x -\frac{x^2}{2}} dx \\
        %  &= \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} x  e^{-\frac{1}{2}(x-1)^2+\frac{1}{2} } dx \\
        %  &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\int_{-\infty}^\infty x  e^{-\frac{1}{2}(x-1)^2 } dx\\
        %  & \mathrm{Let\;} u = x-1 \; \mathrm{then\;} x = u+1\\
        %  &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\int_{-\infty}^\infty (u+1)e^{\frac{-u^2}{2}} du\\
        %  &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}} \left( \int_{-\infty}^\infty ue^{\frac{-u^2}{2}}du +\int_{-\infty}^\infty e^{\frac{-u^2}{2}} du  \right) \\
        %  &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\sqrt{2\pi}   \\
         &= e^{\frac{1}{2}}.\\
    \end{align*}
    If dividing with the standard deviations of $X$ and $e^X$ we get the correlation. To do this we need to calculate the variances of $X$ and $e^X$. We know that $\mathrm{Var}(X) = 1$ but need to calculate the variance of $e^X$. The variance of $e^X$ is calculated using the moment generating function as
    \begin{align*}
        \mathrm{Var}(e^X) &= E[e^{2X}] - E[e^X]^2\\
        &= e^2 - e.
    \end{align*}
    The correlation is then calculated as
    \begin{align*}
        \mathrm{corr}(X,e^X) &= \frac{\mathrm{cov}(x,e^X)}{\sqrt{\mathrm{var}(x)} \sqrt{\mathrm{var}(e^X)}}  \approx 0.76. 
       % & = \frac{e^{\frac{1}{2}}}{1\sqrt{e^2-e}}\\
       % &=\sqrt{\frac{1}{e-1}} \approx 0.76. 
    \end{align*}
    If instead using the copula to calculate the correlation we can see that the correlation is not capturing the true dependence between $X$ and $e^X$. To see this we can use the \gls{PIT} to transform $X$ and $e^X$ into uniform random variables. If we let $F_X(X)=U_1$ be the normal data transformed to uniform random variables and $F_{e^X}(e^X)=U_2$ be the log-normal data transformed to uniform random variables we can see that 
    \begin{align*}
        F_{e^X}(e^X) &= P(e^X \leq e^x)\\
        &= P(\ln(e^X) \leq \ln (e^x))\\
        &=P(X\leq x) = U_2 = U_1.
    \end{align*}
    Since $U_1 = U_2$ we have 
    \begin{align*}
        P(U_1\leq u_1, U_2\leq u_2) = P(U_1\leq u_1, U_1\leq u_2) = \min(u_1,u_2).
    \end{align*}
    This is the upper copula given by the upper Fréchet-Hoeffding bound, which is the copula corresponding to maximum dependence. Hence, correlation underestimates the true dependence between the random variables given that maximum dependence under the correlation framework is one. This underestimation of the correlation is because of the assumption of a normal or students $t$ distribution which is violated with the lognormal variable in the example. This shows how copulas can capture dependence when correlation fails. 

    In \Cref{fig:ExamplePlots} some illustrations of \Cref{ex:CorrelationUnderestimates} are shown. The true copula \gls{CDF} surface is shown in \Cref{fig:TrueCopulaExponential} this can be compared to the copula function surface estimated using correlation in \Cref{fig:CorrelationEstimationExponential}. These two pictures show how the estimated copula is not capturing the true copula reflecting maximum dependence. 
    %\Cref{fig:exponentialDependenceScatterProb} shows the scatter plot of the data in the probability space illustrating what maximum dependence looks like in probability space. 
    \Cref{fig:exponentialDependenceScatterRet} shows the scatter plot of $X$ against $e^X$ in return space. This illustrates that the correlation estimate is insufficient as a dependency measure. This is because correlation fits a straight line to a nonlinear curve in this case. 
    
    % \begin{generalinstructions}
    %     Would be nice to tie this to something in finance. Such as the relationship between stocks returns and derivative prices.

    %     This shows that estimating the correlation in a setting when the different marginals are not both normal can be misleading. This is a problem in finance where one often uses correlation to estimate the dependence between different assets. This is especially true when using correlation to estimate the dependence between stocks and derivatives.
    % \end{generalinstructions}
\end{example}
    

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/TrueCopula.png}
        \subcaption{True copula \gls{CDF} for the example.}
        \label{fig:TrueCopulaExponential}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/EstimatedCopula076.png}
        \subcaption{Estimated copula \gls{CDF} using correlation.}
        \label{fig:CorrelationEstimationExponential}
    \end{minipage}
    %\hfill
    \vfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/ExpXPlot.png}
        \subcaption{Data in return space showing correlation estimate using the regression line.}
        \label{fig:exponentialDependenceScatterRet}
    \end{minipage}
    \caption{Figures illustrating how correlation breaks as a measure of dependence.}
    \label{fig:ExamplePlots}
\end{figure}

Up to now we have not yet provided an example of the usefulness of copulas. The next section will show an example of how copulas are useful in practice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Use for copula
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Use Case for Copulas in Practice}\label{sec:CopulaUseCase}
If there are several sources of randomness present in a system where \gls{MC} methods are used, potential dependence between the sources of randomness has to be taken into account. Copulas are a powerful tool for modeling the dependence structure between random variables. They allow for separation of the dependence and the marginal distributions. By using copulas, we can generate samples from multivariate distributions with specified marginals and a desired dependence structure by generating dependent marginally distributed uniform random numbers. These are then transformed to the desired marginal distributions using the inverse of the marginal \gls{CDF}s by the inverse transform method \Cref{def:InverseTransformMethod}.

Let $U = (U_1,U_2)$ be a point specified by two marginally uniformly distributed random variables $U_1$ and $U_2$ sampled from a copula giving them some dependence. Then random numbers $X = (X_1,X_2)$ with the dependence specified by the copula and desired marginal distributions can be generated by transforming the uniform random numbers using the \gls{ITM}. This is done by using the inverse of the marginal \gls{CDF}s as follows
\begin{align*}
    X_1 = F_1^{-1}(U_1); \\
    X_2 = F_2^{-1}(U_2).
\end{align*}

The usefulness of copulas in sampling is visualized in \Cref{fig:CopulaSampling}. The left figure shows a sample from a Clayton copula with $\alpha = 2$, which will be defined in \Cref{sec:ClaytonCopula}. In the figure the blue points are the data points, in probability space, sampled from the copulas. Along with the the data points the figure shows the distribution of the data points using a histogram per dimension. The right figure shows the same sample as blue points after applying the \gls{ITM} using a standard normal distribution for each marginal. Additionally, the marginal distributions are shown using histograms for each dimension. Note that the \gls{ITM} can be applied to each of the dimensions of the copula data thanks to the fact that copulas by definition have uniform marginals. 

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/ClaytonProbSpace.png}
        \caption{Sample from a Clayton copula with $\alpha = 2$. } 
        \label{fig:ProbabilitySpaceDataClayton}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{3Theory/pictures/ClaytonRetSpace.png}
        \caption{Sample from Clayton copula after applying the \gls{ITM} using a standard normal distribution.}
        \label{fig:ReturnSpaceDataClayton}
    \end{subfigure}
    \caption{Illustration of sampling from a Clayton copula with standard normal marginal distributions.}
    \label{fig:CopulaSampling}
\end{figure}

In the above example we have seen the usefulness of copulas in sampling. The example does not go into the nontrivial task of sampling from a copula. Therefore two methods of sampling from copulas are presented in the appendix in \Cref{sec:ConditionalSampling} and \Cref{sec:AcceptanceRejection}.

For the interested reader \Cref{sec:OtherCopulas} introduces some other widely used copulas. This section is placed in the appendix as it is not vital for understanding the experiments in this thesis. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% neural networks
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Neural Networks}\label{sec:NeuralNetworks}
A full introduction of \gls{NN}s is beyond the scope of this thesis and the interested reader is referred to \Citet[]{Jentzen2023}. Some suggested topics are artificial neural networks, gradient descent, and back propagation. This section will only give a brief introduction to \gls{NN}s and how they can be used for learning functions by just penalizing unwanted behavior. In particular a short description of how to solve differential equations using \gls{NN}s as this will be used to train the neural copula.

A theoretical introduction to solving differential equations using \gls{NN}s can be found in \Citet[pp.~81-84]{KarlssonFaronius1746454} or \Citet[pp.~509-516]{Jentzen2023}. What is however more illustrative of the method of solving differential equations using \gls{NN}s is to show how the method works in practice. This is done in \Cref{ex:NeuralNetworkDifferentialEquation}, showing how to solve a simple differential equation using \gls{NN}s. The example is taken from a video seminar on how to solve Partial Differential Equations using \gls{NN}s by Leah Bar\footnote{See Leah Bar, "Deep Learning Approach to Partial Differential Equations | Leah Bar, OriginAI (PyData TLV June22)", \textit{PyData}, Published: 2022-07-18 \url{https://www.youtube.com/watch?v=f44sFOR296I}, Last Accessed: 2025-05-07.}. 

\begin{example}\label{ex:NeuralNetworkDifferentialEquation}
    \textbf{Solving differential equations with neural networks}\\
    Suppose we want to solve the following differential equation (Newtons law of cooling)
    \begin{align*}
        \frac{dT}{dt} = k(M-T), \quad \; T(0) = T_0 = 100,\; M = -10,\; k = 0.25.
    \end{align*}
    where $T$ is the temperature, $t$ is time, $M$ is the ambient temperature, and $k$ is a constant. This is a simple first order differential equation. The solution to the equation is given by
    \begin{align*}
        T(t) = M + (T_0-M)e^{-kt}.
    \end{align*}
    To solve the equation using a \gls{NN} we can use the following procedure. First, we create a \gls{NN} having input $t$ and output $T$. Second, the \gls{NN} is trained to minimize the loss function specified as 
    \begin{align*}
        \mathrm{loss} = \frac{1}{n} \sum_{i=1}^{n} \left\| \frac{dT(t_i)}{dt} - k(M-T(t_i))\right\|_2^2 + \lambda \left\|T(0) - T_0\right\|,
    \end{align*}
    for $n$ data points $t_i$ sampled from the domain of time. 
    This loss function consists of two parts. The first part is the loss function that penalizes the \gls{NN} for not solving the differential equation. The second part is a penalty term that penalizes the \gls{NN} for not satisfying the initial condition. The loss can easily be calculated using automatic differentiation of the neural network. 
\end{example}
The method described in the above example can be used to train a \gls{NN} to follow certain rules stated in terms of the derivatives of the \gls{NN}. This will be used in the next section to train a \gls{NN} to approximate a copula function.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Neural Copula
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Neural Copula}\label{sec:NeuralCopula}
A \gls{NC} is a method proposed by \Citet[]{ZengWang2022} to use \gls{NN}s to approximate a copula function. 


\subsubsection{Overall Procedure}
The overall procedure when using a \gls{NC} is to fit one \gls{NN} to approximate the \gls{CDF} of each marginal distribution. These \gls{NN}s are then used to transform each dimension of the data to probability space using the \gls{PIT}. The obtained data points are then used for fitting another \gls{NN} approximating the copula function \Citet[p.~4]{ZengWang2022}. 

\subsubsection{Data}
First, we define the observed data as $x^{\mathrm{obs}}\in \mathbb{R}^2 $. To fit the marginal distributions, the data must be normalized to lie in the interval $\mathbb{I}^2 = [0,1]^2$. We normalize the data $x$ by using min max normalization defined as
\begin{align*}
    x_{i,j} = \frac{x_{i,j}^{\mathrm{obs}} - \min_i(x_{j}^{\mathrm{obs}})}{  \max_i(x_{j}^{\mathrm{obs}})- \min_i(x_{j}^{\mathrm{obs}})}.
\end{align*}
The normalized data $x$ is then used to fit a marginal distribution $\hat{F}_j$ to each dimension $x_j, \; \mathrm{where} \; j=\{1,2\}$ if $x$ has two dimensions. 


\subsubsection{Marginal Model Architecture}
A marginal distribution is fitted for each dimension of the data using a \gls{NN} having the following architecture 
\begin{align*}
    \mathrm{Input\;layer:} \; & \mathbf{h}_m^0 = x_j \in \Omega_j = \mathbb{I}; \\
    \mathrm{Hidden\;layer:} \; & \mathbf{h}_m^{k+1} = \mathrm{tanh}(\mathbf{w}_m^{k} \mathbf{h}_m^{k} + \mathbf{b}_m^{k}), \; k \in \{0,1, \dots, l_m -1 \};\\
    \mathrm{Output\;layer:} \; & \hat{F}_j = \mathrm{sigmoid}(\mathbf{w}_m^{l_m} \mathbf{h}_m^{l_m} + \mathbf{b}_m^{l_m}) \in \left[0,1 \right],
\end{align*}
where $\hat{F}_j$ is the estimated marginal \gls{CDF}, $\Omega$ is the entire domain where the data can be, $l_m$ is the number of layers in the network, $\mathbf{w}_m^{k}$ are the weights in the $k$th layer,  $\mathbf{h}_m^{k}$ is the input data in the $k$th layer, and $\mathbf{b}_m^{k}$ is the biases in the $k$th layer \Citet[pp.~5-6]{ZengWang2022}. Note that the weights, biases, and input data are different for each dimension in the data. 

\subsubsection{Marginal Loss Function}\label{sec:NeuralMarginalLoss}
This section defines the loss function for a marginal model $\hat{F}_j$ as described in \Citet[pp.~7-8]{ZengWang2022}. First, we define the datasets that will be used for calculating the loss function. Let $D_{obs}$ be the set of observed and scaled data points $x_j$ for the $j$-th dimension of the data. Also, let $D_u$ be a set of uniformly distributed data points on the domain $\Omega$ of the data. Let $\hat{f}_j$ denote the \gls{PDF} corresponding to $\hat{F}_j$.

The loss function consists of four parts that are designed to ensure that the network fits the data as well as possible whilst following the requirements of a \gls{CDF}. The first part of the loss function maximizes the log likelihood of the fitted \gls{CDF} to the observed data. Since the network minimizes the loss during training, we need the negative log likelihood as the loss. The first part of the loss is defined as
\begin{align*}
    L_1^m = \frac{-1}{|D_{obs}|} \sum_{i \in D_{obs}} \log(\hat{f}_j(x_i)).
\end{align*}

The second part of the loss function ensures that the \gls{PDF} is not negative. This corresponds to the loss function 
\begin{align*}
    L_2^m = \int_{x_{i\in\Omega}} (-\hat{f}(x))^+dx \approx \frac{-1}{|D_{u}|} \sum_{i \in D_{u}} (-\hat{f}_j(x_i))^+.
\end{align*}
The third part of the loss function ensures that the integral of $\hat{f}$ over $\Omega$ is one as stated in \Cref{rem:pdfProperties}. The loss can be formulated as 
\begin{align*}
    L_3^m = \left | 1- \int_{x\in \Omega} \hat{f}(x) dx    \right | \approx \left | 1- \frac{1}{|D_{u}|} \sum_{i \in D_{u}} \hat{f}_j(x_i)  \right |.
\end{align*}
The final loss ensures that the \gls{CDF} begins at zero and ends at one. This is ensured by the loss
\begin{align*}
    L_4^m = \hat{F}_j(0) + |1- \hat{F}_j(1) |.
\end{align*}

The total loss can be formulated as a linear combination of the loss components. 
\begin{align*}
    L^m = \sum_{i=1}^4 \lambda_i L_i^m,
\end{align*}
where $\lambda_i$ is the weigh put on the $i$:th loss component. 

\subsubsection{Copula Model Architecture} 
When having transformed the data to probability space using the fitted marginal \gls{CDF}s a new dataset $u = (u_1,u_2) = (F_1(x_1), F_2(x_2))$ is obtained. 

The copula model $\hat{C}$ is defined as 
\begin{align*}
    \mathrm{Input\;layer:} \; & \mathbf{h}_c^0 = u \in \Omega^2 = \mathbb{I}^2; \\
    \mathrm{Hidden\;layer:} \; & \mathbf{h}_c^{k+1} = \mathrm{tanh}(\mathbf{w}_c^{k} \mathbf{h}_c^{k} + \mathbf{b}_c^{k}), \; k \in \{0,1, \dots, l_c -1 \};\\
    \mathrm{Output\;layer:} \; & \hat{C} = \mathrm{sigmoid}(\mathbf{w}_c^{l_c} \mathbf{h}_c^{l_c} + \mathbf{b}_c^{l_c}) \in \left[0,1 \right],
\end{align*}
as in \Citet[pp.~6-7]{ZengWang2022}.

\subsubsection{Copula Loss Function}\label{sec:NeuralCopulaLoss}
Before defining the copula loss function, we need to define the different data sets used to compute the loss. Additionally, we need to define the copula \gls{CDF} and its corresponding copula \gls{PDF}. 

First, we define the datasets. Let $D_{\mathrm{obs}}$ be the observed data points $u \in \Omega_1 \times \Omega_2  = \mathbb{I}^2$. Let $D_{u}$ be uniformly distributed data on $\mathbb{I}^2$. Let $D_{\bar{u}}$ be uniformly distributed points on the upper boundary of the unit square $\mathbb{I}^2$. Let $D_{\underline{u}}$ be a set of points uniformly distributed on the lower boundary of the unit square $\mathbb{I}$. In \Cref{fig:datasetsNC} the datasets used to train the \gls{NC} are visualized. The blue data points are uniformly distributed over the upper boundaries of the region where one variable is one. The grey points are uniformly distributed on the lower boundaries of the region where one of the variables is zero. The red data points are the observed data in probability space. The black data points are uniformly distributed over the interval. 

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{3Theory/pictures/DatasetsNC.png}
    \caption{The different datasets used for training the \gls{NC} visualized.}
    \label{fig:datasetsNC}
\end{figure}

The copula model itself approximates a copula function which is a \gls{CDF} on the unit square $\mathbb{I}^2$. The copula function is denoted in terms of its uniform marginals $u$ consisting of $u_1$ and $u_2$. 
\begin{align*}
    \hat{C}(u) = \hat{C}(u_1,u_2) 
\end{align*}
The corresponding copula \gls{PDF} can be written as  
\begin{align*}
    \hat{c}(u) = \frac{\partial^2 \hat{C}(u_1,u_2)}{\partial u_1 \partial u_2}. 
\end{align*}
 
Now we are ready to introduce the copula loss function as in \Citet[pp.~8-11]{ZengWang2022}, consisting of five parts. The first part, as in the marginal model, maximizes the log likelihood and is defined as
\begin{align*}
    L_1^c = \frac{-1}{|D_{obs}|} \sum_{i \in D_{obs}} \log(\hat{c}(u_i)).
\end{align*}
The second term ensures positivity of the copula \gls{PDF} and is defined by
\begin{align*}
    L_2^c = \int_{u_1\in\Omega}\int_{u_2\in\Omega} (-\hat{c}(u))^+du_1du_2 \approx \frac{-1}{|D_{u}|} \sum_{i \in D_{u}} (-\hat{c}(u_i))^+.
\end{align*}
The third part ensures that the copula PDF integrates to one and is defined as
\begin{align*}
    L_3^c = \left | 1- \int_{u_1\in\Omega}\int_{u_2\in\Omega} \hat{c}(u_j) du_1 du_2   \right | \approx \left | 1- \frac{1}{|D_{\mathrm{u}}|^2} \sum_{i \in D_{u}} \hat{c}(u_i)  \right |.
\end{align*}
The fourth term is supposed to ensure that the copula function is grounded and that it has margins. It is defined as
\begin{align*}
    L_4^c = \sum_{i \in D_{\underline{u}}} \hat{C}(u_i) + \sum_{i \in D_{\bar{u}}} \left| \hat{C}(u_i) - \max(u_i) \right|.
\end{align*}
The fifth term  ensures that the copula is $2$-increasing and is defined as
\begin{align*}
    L_5^c = \frac{1}{|D_{u}|} \sum_{i \in D_{u}} \left| \hat{C}(u_i) - \frac{1}{|D_{\mathrm{obs}}|}\sum_{j\in D_{\mathrm{obs}}} \mathrm{flag}(u_i,u_j) \right|,
\end{align*}
where $\mathrm{flag(x,y)}$ is defined as 
\begin{align*}
    \mathrm{flag}(x,y) =  
    \begin{cases}
        1 \; \mathrm{if} \; \forall j \leq 2, y_j < x_j\\
        0 \; \mathrm{otherwise}.
    \end{cases}
\end{align*}




That is, the flag function compares two points $x$ and $y$ and gives back one if all dimensions $x$ is greater than $y$ in all dimensions. What this does in the loss function is that for each point in $D_u$ the copula \gls{CDF} is compared to the fraction of points in $D_{obs}$ that are smaller than the point in $D_u$. The value of the copula function and the fraction of points below should be similar if the data is 2-increasing.   

As for the marginal model, the total loss is given by a linear combination of the loss terms defined as follows
\begin{align*}
    L^c = \sum_{i=1}^5 \lambda_i L_i^c,
\end{align*}
where $\lambda_i$ is the weight assigned to each part loss term. 


\subsubsection{Fittig and Sampling Procedure}\label{sec:NeuralCopulaFittingAndSampling}
\textbf{Fitting}\\
In the neural copula article the fitting procedure is as follows: by \Citet[p.~4]{ZengWang2022}
First the data is normalized to lie in the interval between zero and one using min-max normalization. The normalized data is then used to fit the \gls{NC} to data by first fitting marginal distributions to each dimension of the data. This is done by training \gls{NN}s that minimize the marginal loss function defined in \Cref{sec:NeuralMarginalLoss} for each dimension. The copula is fitted by training another \gls{NN} that minimizes the copula loss function defined in \Cref{sec:NeuralCopulaLoss}. 

\textbf{Sampling}\\
To sample from the \gls{NC} we first sample the copula model using acceptance rejection sampling as described in \Cref{sec:AcceptanceRejection}. This can be done since the copula is essentially a distribution which we can find the density function of. Sampling the copula yields data points in probability space. 

To get a sample from the joint distribution, in the space where the data was observed, we need to transform the sampled data points to the marginal distributions. Here there are different alternatives of how to sample. Either one can sample from the fitted marginal models or one can sample from any other probability distribution. In either case the sampled data in probability space is transformed using the inverse of the fitted marginal \gls{CDF}, using the \gls{ITM} described in \Cref{def:InverseTransformMethod}. The resulting data points should be a sample from the joint distribution if the copula and the marginals are fitted sufficiently well. 

\begin{remark}
     To make the sampling from the marginal \gls{CDF} more efficient, polynomial fitting was tried. This did not work well as Runges phenomenon made the interpolating line very squiggly which is not desired. An alternative that has not been tested in this thesis is to interpolate a set of solved points using spline functions. This would be a good alternative since it would not suffer from the same problems as polynomial fitting, now the bisection algorithm is used to solve for points on the inverse \gls{CDF}.   
\end{remark}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Goodness of fit measures
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Goodness of Fit Measure}\label{sec:GoodnessOfFit}
This section describes how to measure how similar two datasets are. This is done using the Wasserstein distance. This can be thought of as the distance we would need to move one distribution to match another. It is often described as moving a pile of dirt from one place to another where the pile represents the \gls{PDF}. The distance is the minimum cost of moving the dirt. The cost is defined as the distance moved times the amount of dirt moved. If thinking about the dirt in terms of individual grains of sand we can think of the cost as the average distance a grain of sand has to be moved for one pile to become identical to another pile. To solve this problem one needs to have the same amount of grains in each pile and therefore the two distributions need to be of the same size. The task of finding the combination of grains that minimizes the average distance of the dirt moved is highly complex and unfeasible for large datasets. Therefore a method of approximating this is needed. 

The distance approximation used is defined as 
\begin{align*}
    \mathrm{dist}(\mu,\nu) = \left( \sum_{i=1}^n \sum_{j=1}^m |\hat F_\mu(x_i,y_j) - \hat F_\nu(x_i,y_j)|^p \Delta x_i \Delta y_j \right)^{\frac{1}{p}},
\end{align*}
where $\Delta x_i$ and $\Delta y_j$ are the step sizes in the $x$ and $y$ dimensions respectively. A full derivation of this distance measure can be found in \Cref{sec:DistanceDerivation}. We encourage reading the section and look at the figures to get an understanding of what this distance measure is despite it not being crucial for understanding the experiment.  




% First the Wasserstein distance is defined. 
% Wasserstein distance is  (from wikipedia)
% \begin{align*}
%     W_p(\mu,\nu) = \inf_{\gamma \in \Gamma(\mu,\nu)} \left( \mathbf{E}_{(x,y)\sim \gamma} d(x,y)^p \right)^{\frac{1}{p}},
% \end{align*}
% where $\Gamma$ is the set of all copulings, $\mu, \nu$ are probability measures and $d$ is a distance function. 


% The minimum cost difference can be written as (from Optimal Transport and Wasserstein Distance)
% \begin{align*}
%     C = \inf_{\gamma \in \Gamma(\mu,\nu)} \left( \int_{\mathbb{R}^2} d(x,y)^p d\gamma(x,y) \right)^{\frac{1}{p}},
% \end{align*}

%If $d(x,y)$ is the euclidean distance we can write the Wasserstein distance as (from Optimal Transport and Wasserstein Distance)



