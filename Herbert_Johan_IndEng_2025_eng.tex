% @Author: Kevin Kamm
% @Date:   2024-05-31 08:51:32
% @Last Modified by:   Kevin Kamm
% @Last Modified time: 2024-09-10 09:46:48
\documentclass[%
a4paper,							
11pt,								
bibliography=totoc,						
abstracton=true					
]
{scrartcl}
\usepackage[pagewise]{lineno}
% \linenumbers % Comment out for final version
\usepackage[a4paper,left=3.0cm,right=2.5cm, top=2.5cm, bottom=3.0cm]{geometry}
\usepackage[headsepline=.4pt,footsepline=.4pt,automark,autooneside=false]{scrlayer-scrpage}
\pagestyle{scrheadings} 
\automark[subsection]{section} 
\automark*[subsubsection]{subsection}
\ihead{\scriptsize\rightmark}\chead{ }
\cfoot{\pagemark}
\usepackage{subcaption}

\usepackage[swedish,english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern} %latin modern
\usepackage{setspace} % 1.5-line spacing
\usepackage{csquotes} % provides \enquote
\usepackage{epigraph} % provides \epigraph
\setlength\epigraphwidth{.6\textwidth}
\setlength\epigraphrule{0pt}
\setlength{\parskip}{1em}
\setlength{\parindent}{0pt}
\interfootnotelinepenalty=10000 % avoid footnote page breaks
\usepackage{abstract}

\usepackage{calc}
\usepackage{xspace} % provides \xspace

% Math symbols & environments
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm,thmtools}
\usepackage{mathtools}
\usepackage{bbm}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

% Figures & color
\usepackage{graphicx} 
\usepackage{float}
\usepackage[section]{placeins} % float barrier after sections
\usepackage{pdflscape} % provides \includepdf
\usepackage[format=plain]{caption}
\usepackage{xcolor}
\usepackage{fancyvrb}
\usepackage{tikz}
\usetikzlibrary{calc,positioning,arrows.meta}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}

% Code Highlighting & Todo Notes
\usepackage{minted}
\usepackage{todonotes} % provides \todo

% Tables & Lists
\usepackage{paralist} % provides compact environments
\usepackage{tabularx} % provides tabularx
\usepackage{booktabs} % provides \toprule
\usepackage{multirow}
\usepackage{multicol}
\usepackage{diagbox} % provides \diagbox


\usepackage{subcaption}  % in your preamble

\usepackage{graphicx}
\usepackage{subcaption}



\usepackage[
	backend=bibtex,
	style=authoryear-comp,
	maxbibnames=9,
	maxcitenames=2,
	dashed=false,
	natbib=true,
	sortcites=true,
	block=space
]{biblatex}
\renewcommand*{\mkbibnamefamily}[1]{\textsc{#1}}
\renewcommand*{\mkbibnamegiven}[1]{\textsc{#1}}
\renewcommand*{\finalnamedelim}{\ \bibstring{and}\ }
\renewcommand*{\bibfont}{\footnotesize}
\addbibresource{literature.bib} 

\usepackage{hyperref}
\usepackage{cleveref} % provides \Cref
\hypersetup{
    colorlinks,
    linkcolor={red},
    citecolor={blue},
    urlcolor={blue}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% URL fix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{url}
\def\UrlBreaks{\do\/\do-\do\&\do.}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Macros
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\1}{\mathbbm{1}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\D}{\mathrm{Dom \;}}
\DeclareMathOperator*{\argmin}{argmin}


%% Verbatim examples
\SaveVerb{python}=(Intel-)Python 3.10=
\newcommand{\python}{\protect\UseVerb{python}\xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Glossary
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{glossaries}
\newacronym{PDF}{PDF}{Probability Density Function}
\newacronym{CDF}{CDF}{Cumulative Distribution Function}
\newacronym{NN}{NN}{Neural Network}
\newacronym{NC}{NC}{Neural Copula}
\newacronym{PIT}{PIT}{Probability Integral Transform}
\newacronym{GBM}{GBM}{Geometric Brownian Motion}
\newacronym{MLE}{MLE}{Maximum Likelihood Estimation}
\newacronym{CSD}{CSD}{Central Securities Depository}
\newacronym{SPAN}{SPAN}{Standard Portfolio Analysis of Risk}
\newacronym{VaR}{VaR}{Value at Risk}
\newacronym{MC}{MC}{Monte Carlo}
\newacronym{SDE}{SDE}{Stochastic Differential Equation}
\newacronym{ITM}{ITM}{Inverse Transform Method}
\newacronym{MAE}{MAE}{Mean absolute error}
\newacronym{ES}{ES}{Expected Shortfall}


\makeglossaries
\newglossarystyle{mylist}{%
  \setglossarystyle{list}% base this style on the list style
  \renewcommand*{\glossentry}[2]{%
    \item[\glsentryitem{##1}\glstarget{##1}{\glossentryname{##1}}]%
\glossentrydesc{##1}\glspostdescription\space}%
}
\setglossarystyle{mylist}
\renewcommand*{\glstextformat}[1]{\color{black}#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Color comment boxes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xcolor}
\usepackage{tcolorbox}

% Define a custom command for general instructions
\newtcolorbox{generalinstructions}{
    colback=orange!90, % More saturated orange background
    colframe=black, % Stronger orange border
    boxrule=1.2pt, % Slightly thicker border for sharpness
    arc=2pt, % Less rounded corners for a sharper look
    width=\linewidth, % Full width box
    before skip=10pt, % Space before the box
    after skip=10pt, % Space after the box
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Begin Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\onehalfspacing
\pagestyle{plain}
\pagenumbering{roman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title Page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}
    \begin{center}
    \begin{tikzpicture}[overlay,remember picture,align=center,anchor=north]
        \path let \p1 = (current page.north) in coordinate (pageNorth) at (0,\y1);
        \path let \p1 = ($(current page.north)!0.5!(current page.south)$) in coordinate (pageCenter) at (0,\y1);
        \node[align=center,anchor=north, yshift=-1cm] (LogoUmU) at (pageNorth) {\includegraphics{Figures/LogoUmU.png}};
        \node[align=center,anchor=north, below = of LogoUmU.south] (BackgroundUmu) {\includegraphics[width=.9\paperwidth]{Figures/Titlepage.jpg}};
        \node[anchor=south west,align=left] at (BackgroundUmu.south west) {\color{white}
            \begin{tabular}{lll}
                Supervisors & Kevin Kamm & Umeå University\\
                            & Victor Jonsson & Vermiculus Financial Technology\\
                Examiner & Christian Ewald & Umeå University
            \end{tabular}
        };
    \end{tikzpicture}
    \end{center}
\vspace*{5cm}
\begin{center}
    {%  
        \color{white}
        \noindent
        \Huge
        \bfseries 
        \sffamily
        Johans Thesis
    }\\[1em]
    {%
        \color{white}
        \noindent
        \Large
        \bfseries 
        \sffamily
        Subtitle of Thesis
    }%
\end{center}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%\footnotetext[1]{Department of Mathematics and Statistics, Umeå University, Sweden}
\footnotetext[2]{johe6227@student.umu.se}
%\footnotetext[3]{E-mail: name.surname@umu.se}

\begin{center}
    \color{white}
    \large
    Johan Herbert%
    %\footnotemark[1]{}%\textsuperscript{,}%
    \footnotemark[2]{}
    \hspace{2em}
    % Name Surname%
    % \footnotemark[1]{}\textsuperscript{,}%
    % \footnotemark[3]{}
    \hspace{2em}
\end{center}
\begin{center}
    \color{white}
    \large
    Examination Date: \today
\end{center}
\vfill
\begin{center}
    Master thesis, 30 ECTS\\
    M.Sc in Industrial Engineering and Management, 300 ECTS\\
    Spring term 2025
\end{center}


\renewcommand{\thefootnote}{\arabic{footnote}}


\thispagestyle{empty}
\end{titlepage}
\pagenumbering{Roman}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstracts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
    % This is the english abstract.
    % This thesis investigates the use of copulas for modeling dependency structures between financial asset returns, with a specific focus on a recently introduced method known as the \gls{NC}. The work is carried out in collaboration with Vermiculus Financial Technology and aims to enhance risk modeling in clearing systems. Traditional copulas are compared to the \gls{NC} in terms of performance, adaptability, and applicability to different dependency structures. The study involves the development of an alternative method for fitting marginal distributions and a practical sampling approach for the \gls{NC}. Simulated data is used to evaluate the methods under controlled conditions. The results show that the \gls{NC} cannot provide competitive performance compared to other copulas in capturing complex dependencies. This work contributes to the understanding of when and how to use neural copulas in financial risk modeling.

    This thesis explores the use of neural networks for estimating copula functions, with the goal of modeling the joint distribution of financial time series. Specifically, it evaluates a recently proposed neural copula (NC) approach that incorporates copula properties directly into the neural network's loss function. Three experiments were conducted to assess the model’s performance. The first confirmed the adequacy of the NC's marginal distribution modeling. The second identified optimal hyperparameters for stable training of the NC. The third compared the NC to traditional copula methods using synthetic data, showing that the NC did not outperform classical methods in the tested scenarios. Contributions of this work include a practical sampling method for the NC, an investigation of alternative marginal fitting techniques, and a critical comparison across copula models. The thesis concludes with reflections on the limitations and learning outcomes, and proposes several directions for future research, such as improving numerical stability, extending the NC to high-dimensional settings, and integrating copulas into dynamic volatility models.
\end{abstract}

\newpage
\renewcommand{\abstractname}{Sammanfattning}
\begin{abstract}
    % Det är svenska sammanfattning.
    % Denna masteruppsats undersöker användningen av copulor för att modellera beroendestrukturer mellan finansiella tillgångars avkastningar, med särskilt fokus på en nyligen introducerad metod kallad \gls{NC}. Arbetet har genomförts i samarbete med Vermiculus Financial Technology och syftar till att förbättra riskmodellering i clearingsystem. Traditionella copulor jämförs med \gls{NC} avseende prestanda, anpassningsförmåga och tillämplighet på olika typer av beroenden. Studien omfattar utvecklingen av en alternativ metod för att anpassa marginalfördelningar samt ett praktiskt tillvägagångssätt för slumptalsgenerering från \gls{NC}. Simulerad data används för att utvärdera metoderna under kontrollerade förhållanden. Resultaten visar att \gls{NC} inte producerar bättre resultat än övriga traditionella metoder vid modellering av komplexa beroenden, även om dess effektivitet är beroende av datakaraktäristik och korrekt träning. Uppsatsen bidrar till en ökad förståelse för när och hur neural copula kan användas inom finansiell riskmodellering.

    Denna avhandling undersöker användningen av neurala nätverk för att uppskatta kopulafunktioner, med målet att modellera den gemensamma fördelningen av finansiella tidsserier. Särskilt utvärderas en nyligen föreslagen metod med neurala kopulor (NC) som integrerar kopulaegenskaper direkt i det neurala nätverkets förlustfunktion. Tre experiment genomfördes för att bedöma modellens prestanda. Det första bekräftade att NC:n på ett tillfredsställande sätt modellerar de marginala fördelningarna. Det andra identifierade optimala hyperparametrar för stabil träning av NC:n. Det tredje jämförde NC:n med traditionella kopulametoder med syntetiska data och visade att NC:n inte överträffade klassiska metoder i de testade scenarierna. Avhandlingens bidrag inkluderar en praktisk samplingsmetod för NC:n, en undersökning av alternativa tekniker för anpassning av marginalfördelningar samt en kritisk jämförelse mellan olika kopulamodeller. Avslutningsvis diskuteras begränsningar och lärdomar från arbetet, samt föreslås flera riktningar för framtida forskning, såsom att förbättra numerisk stabilitet, utöka NC:n till högdimensionella tillämpningar och integrera kopulor i dynamiska volatilitetmodeller.

\end{abstract}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}
I would like to express my sincere gratitude to my supervisor, Kevin Kamm at Umeå University, for his unwavering support, insightful guidance, and enthusiasm throughout this thesis. His expertise and mentorship have been instrumental in shaping this work and continually challenging me to think critically and push boundaries.

I am also deeply thankful to Victor Jonsson and Vermiculus Financial Technology for the opportunity to collaborate on this project. Their warm welcome, encouragement, and practical support created a truly rewarding and engaging experience.

Lastly, I would like to thank my family and friends for their continued support, patience, and encouragement throughout this journey. Your belief in me has made all the difference.

Johan Herbert\\
Stockholm, Sweden\\
\today 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Glossaries & Table of Contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \printglossary
\clearpage
\newpage
{\hypersetup{linkcolor=black}
\tableofcontents
}
\newpage
\pagenumbering{arabic}
\pagestyle{scrheadings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}\label{sec:Introduction}
\input{1Introduction/Introduction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Theory
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Theory}\label{sec:theory}
\input{3Theory/Theory}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Methodology 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology}\label{sec:Method}
\input{4Method/Method}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Results and Discussion 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Discussion}\label{sec:Results}
\input{5ResultsDiscussion/ResultsAndDiscussion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{sec:Conclusion}
\input{6Conclusion/Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \nocite{*}
\printbibliography




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Additional portfolio plots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Additional plots of generated data}\label{sec:CopulaResultsData}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio1Gauss.png}
        \subcaption*{Gaussian copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio1Students.png}
        \subcaption*{Students $t$ copula}
    \end{minipage}
    \vfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio1Clayton.png}
        \subcaption*{Clayton copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio1Neural.png}
        \subcaption*{Neural copula}
    \end{minipage}
    \caption{Fitted neural copula surfaces for Gaussian $\rho=0$ portfolio.}
    \label{fig:GeneratedDataGaussian0}
\end{figure}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio2Gauss.png}
        \subcaption*{Gaussian copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio2Students.png}
        \subcaption*{Students $t$ copula}
    \end{minipage}
    \vfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio2Clayton.png}
        \subcaption*{Clayton copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio2Neural.png}
        \subcaption*{Neural copula}
    \end{minipage}
    \caption{Fitted neural copula surfaces for Gaussian $\rho=0.7$ portfolio.}
    \label{fig:GeneratedDataGaussian07}
\end{figure}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio3Gauss.png}
        \subcaption*{Gaussian copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio3Students.png}
        \subcaption*{Students $t$ copula}
    \end{minipage}
    \vfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio3Clayton.png}
        \subcaption*{Clayton copula}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/ResultPortfolio3Neural.png}
        \subcaption*{Neural copula}
    \end{minipage}
    \caption{Fitted neural copula surfaces for Students $\rho=-0.8$ , $\nu = 3$ portfolio.}
    \label{fig:GeneratedDataStudents}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Copula surfaces
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Copula surface plots}\label{sec:CopulaSurfacesPlots}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaSurface1.png}
        \subcaption*{Gaussian $\rho=0$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaSurface2.png}
        \subcaption*{Gaussian $\rho=0.7$}
    \end{minipage}
    \vfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaSurface3.png}
        \subcaption*{Students $\rho=-0.8$ , $\nu = 3$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaSurface4.png}
        \subcaption*{Clayton $\alpha=4$}
    \end{minipage}

    \caption{Copula surfaces for the different datasets.}
    \label{fig:NeuralCopulaSurface}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Copula gradients
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Copula gradient plots}\label{sec:CopulaGradientsPlots}
\begin{figure}[H]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaGradient1.png}
        \subcaption*{Gaussian $\rho=0.7$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaGradient2.png}
        \subcaption*{Gaussian $\rho=0.7$}
    \end{minipage}
    \vfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaGradient3.png}
        \subcaption*{Students $\rho=-0.8$ , $\nu = 3$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{5ResultsDiscussion/pictures/PortfolioTest/CopulaGradient4.png}
        \subcaption*{Clayton $\alpha=4$}
    \end{minipage}
    \caption{Copula density surfaces for the different datasets.}
    \label{fig:NeuralCopulaGradient}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Example of Correlation not working
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Correlation Underestimating Dependence }\label{sec:CorrelationUnderestimates}
\begin{example} 
    \textbf{Correlation underestimates the true dependence} 
    Let $X$ be a random variable such that, $X \sim N(0,1)$. Obviously, $X$ and $e^X$ are dependent. The covariance, $\mathrm{Cov}(X,e^X)$ is
    \begin{align*}
        \mathrm{Cov}(X,e^X) &= E \left[  (X-E\left[  X \right])(e^X-E\left[  e^X \right])  \right]\\
         &=  E \left[  X(e^X-E\left[  e^X \right]) \right]\\
         &= E \left[  Xe^X  \right] - E \left[  X E \left[  e^X \right] \right]\\
         &= E \left[  Xe^X  \right]\\
         &= \int_{-\infty}^\infty xe^x \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}} dx\\ %by definition of expectation for Cont. rand. var. 
         &=  \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} x  e^{x -\frac{x^2}{2}} dx \\
         &= \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} x  e^{-\frac{1}{2}(x-1)^2+\frac{1}{2} } dx \\
         &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\int_{-\infty}^\infty x  e^{-\frac{1}{2}(x-1)^2 } dx\\
         & \mathrm{Let\;} u = x-1 \; \mathrm{then\;} x = u+1\\
         &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\int_{-\infty}^\infty (u+1)e^{\frac{-u^2}{2}} du\\
         &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}} \left( \int_{-\infty}^\infty ue^{\frac{-u^2}{2}}du +\int_{-\infty}^\infty e^{\frac{-u^2}{2}} du  \right) \\
         &= \frac{e^\frac{1}{2}}{\sqrt{2\pi}}\sqrt{2\pi}   \\
         &= e^{\frac{1}{2}}.
    \end{align*}
    If dividing with the standard deviations of $X$ and $e^X$ we get the correlation. To do this we need to calculate the variances of $X$ and $e^X$. We know that $\mathrm{Var}(X) = 1$ but need to calculate the variance of $e^X$. The variance of $e^X$ is calculated as
    \begin{align*}
        \mathrm{Var}(e^X) &= E[e^{2X}] - E[e^X]^2\\
        &= e^2 - e.\\
    \end{align*}
    The correlation is then calculated as
    \begin{align*}
        \mathrm{corr}(X,e^X) &= \frac{\mathrm{cov}(x,e^X)}{\sqrt{\mathrm{var}(x)} \sqrt{\mathrm{var}(e^X)}}\\
        & = \frac{e^{\frac{1}{2}}}{1\sqrt{e^2-e}}\\
        &=\sqrt{\frac{1}{e-1}} \approx 0.76. 
    \end{align*}
    If instead using the copula to calculate the correlation we can see that the correlation is not capturing the true dependence between $X$ and $e^X$. To see this we can use the \gls{PIT} to transform $X$ and $e^X$ into uniform random variables. If we let $F_X(X)=U_1$ be the normal data transformed to uniform random variables and $F_{e^X}(e^X)=U_2$ be the log-normal data transformed to uniform random variables we can see that 
    \begin{align*}
        F_{e^X}(e^X) &= P(e^X \leq e^x)\\
        &= P(\ln(e^X) \leq \ln (e^x))\\
        &=P(X\leq x) = U2 = U1.
    \end{align*}
    Since $U_1 = U_2$ we have 
    \begin{align*}
        P(U_1\leq u1, U_2\leq u2) = P(U_1\leq u1, U_1\leq u2) = \min(u_1,u_2).
    \end{align*}
    This is the upper copula given by the upper Fréchet-Hoeffding bound, which is the copula corresponding to maximum dependence. Hence, correlation underestimates the true dependence between the random variables given that maximum dependence under the correlation framework is one. This underestimation of the correlation is because of the assumption of a normal or students $t$ distribution which is violated with the lognormal variable in the example. This shows how copulas can capture dependence when correlation fails. 

    In \Cref{fig:ExamplePlots} some illustrations of the example are shown. The the true copula \gls{CDF} is shown in \Cref{fig:TrueCopulaExponential} this can be compared to the estimated copula using correlation in \Cref{fig:CorrelationEstimationExponential}. %\Cref{fig:exponentialDependenceScatterProb} shows the scatter plot of the data in the probability space illustating what maximum dependence looks like in probability space. 
    \Cref{fig:exponentialDependenceScatterRet} shows the scatter plot of the data in the return space. This illustrates why correlation is insufficient as a dependency measure when the underlying dependence is non-linear. 
    
    % \begin{generalinstructions}
    %     Would be nice to tie this to something in finance. Such as the relationship between stocks returns and derivative prices.

    %     This shows that estimating the correlation in a setting when the different marginals are not both normal can be misleading. This is a problem in finance where one often uses correlation to estimate the dependence between different assets. This is especially true when using correlation to estimate the dependence between stocks and derivatives.
    % \end{generalinstructions}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Distance measure derivation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Distance Measure Derivation}\label{sec:DistanceDerivation}
The Wasserstein distance is defined as in \Citet[p.~1032]{hallin2021}. Let $\mu$ and $\nu$ be two probability measures on $\mathbb{R}^2$ and let $d$ be some distance measure. The Wasserstein distance is defined as the infimum of the cost of moving the dirt from one distribution to another. The cost is defined as the average distance moved times the amount of dirt moved. The Wasserstein distance is then given by
\begin{align*}
    W_p(\mu,\nu) = \inf_{\gamma \in \Gamma(\mu,\nu)} \left( \int_{\mathbb{R}^2} d(x,y)^p d\gamma(x,y) \right)^{\frac{1}{p}}.
\end{align*}


It can be calculated between two equally sized sets of data points by
\begin{align*}
    W_p(\mu,\nu) =  \inf_{\pi} \left( \frac{1}{n} \sum_{i=1}^n \| X_i - Y_{\pi(i)}  \|^p \right)^{\frac{1}{p}},
\end{align*} 


where $d$ is replaced by the euclidean distance\footnote{See \url{https://www.stat.cmu.edu/~larry/=sml/Opt.pdf}. \textit{Optimal Transport and Wasserstein Distance} p.12. Larry Wasserman. Last Accessed 2025-05-15.}. This is the linear assignment of points between the two sets having the smallest distance between them. $\pi$ can be viewed as an operator that chooses the best assignment of points between the two sets. The distance is then the average distance between the points in the two sets. This problem has high cubic complexity and is therefore really inefficient when the number of points is large. This distance is illustrated in \Cref{fig:WassersteinDistance} where two datasets are displayed. The Wasserstein distance is the minimum distance of points moved that makes the two distributions identical. The transportation that results in the smallest distance is shown in the figure as the lines between the points. 
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{3Theory/pictures/WassersteinIllustrated.png}
    \caption{Illustration of the Wasserstein distance between two distributions. The distance is the average distance between the points in the two distributions.}
    \label{fig:WassersteinDistance}
\end{figure}


In one dimension the Wasswerstein distance can be written\footnote{See \url{https://www.stat.cmu.edu/~larry/=sml/Opt.pdf}. \textit{Optimal Transport and Wasserstein Distance} p.4. Larry Wasserman. Last Accessed 2025-05-15.} as 
\begin{align*}
    W_p(\mu,\nu) = \left(  \int_{0}^1 |F_\mu(q)^{-1} - F_\nu(q)^{-1}|^p dq \right)^{\frac{1}{p}}.
\end{align*}
From this we obtain through a change of variables that the Wasserstein distance can be written as
\begin{align*}
    W_p(\mu,\nu) = \left( \int_{\mathbb{R}} |F_\mu(x) - F_\nu(x)|^p dx \right)^{\frac{1}{p}}. 
\end{align*}

This motivates that the integral of the absolute or squared differences between two \gls{CDF}s can be used as a distance measure between the distributions. Note that the following can no longer be called the Wasserstein distance. In two dimensions we therefore define our own distance measure between distributions as
\begin{align*}
    \mathrm{dist}(\mu,\nu) = \left(\iint_{\mathbb{R}^2} |F_\mu(x,y) - F_\nu(x,y)|^p dx dy \right) ^{\frac{1}{p}},
\end{align*}
where $F_\mu$ and $F_\nu$ are the \gls{CDF}s of the two distributions. These distributions are estimated using kernel density estimation with the gaussian kernel over a grid of points. After normalizing the densities to create a distribution, this gives estimates of the \gls{PDF}s for each data set. If computing the cumulative sum of the approximate \gls{PDF}s in each dimension we get an approximated \gls{CDF} of the data. We denote the estimated \gls{CDF}s by $\hat F_\mu$ and $\hat F_\nu$. 

The distance is then approximated by numerical integration over the grid of points as
\begin{align*}
    \mathrm{dist}(\mu,\nu) = \left( \sum_{i=1}^n \sum_{j=1}^m |\hat F_\mu(x_i,y_j) - \hat F_\nu(x_i,y_j)|^p \Delta x_i \Delta y_j \right)^{\frac{1}{p}},
\end{align*}
where $\Delta x_i$ and $\Delta y_j$ are the step sizes in the $x$ and $y$ dimensions respectively. The distance is then calculated as the average distance between the two distributions. The density estimates and the corresponding CDFs are illustrated in \Cref{fig:ApproxWasserstein}. The estimated \gls{PDF}s are shown in \Cref{fig:density1} and \Cref{fig:density2}. The estimated \gls{CDF}s are shown in \Cref{fig:dist1} and \Cref{fig:dist2}. The difference between the two distributions is shown in \Cref{fig:diffDist1and2} and the distance approximation is then calculated as the average distance between the two distributions. That is, the volume under the surface in \Cref{fig:diffDist1and2}. 


\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/densityDist2.png}
        \caption{Density estimation of the first distribution.}
        \label{fig:density1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/densityDist1.png}
        \caption{Density estimation of the second distribution.}
        \label{fig:density2}
    \end{subfigure}
    \vfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/CDFDist2.png}
        \caption{Distribution function estimate of the first distribution.}
        \label{fig:dist1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/CDFDist1.png}
        \caption{Distribution function estimate of the second distribution.}
        \label{fig:dist2}
    \end{subfigure}
    
    \vfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3Theory/pictures/diffDist1and2.png}
        \caption{Difference between the two distributions.}
        \label{fig:diffDist1and2}
    \end{subfigure}
    \caption{Density and CDF plots used in the distance calculation.}
    \label{fig:ApproxWasserstein}
\end{figure}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Code
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Code}\label{sec:Code}
In this section, the code used in this thesis is provided. Given the amount of code, we have chosen to provide the Github link to the code repository. The code is available at \url{https://github.com/JohanHerbert/ThesisWork}. The main tests are \todo{Fill in this when code is cleaned up. Make Repo public}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Further Experiments
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Further Experiments}\label{sec:FurtherExperiments}
% If you have done extensive testing but do not want to include all of them in the main body of the thesis, then you can place them in the appendix and refer to them in the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Declarations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Confidentiality}
The authors have no relevant confidentiality agreements to disclose.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Declarations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Declarations}
The authors have no relevant financial or non-financial interests to disclose.
\end{document}

